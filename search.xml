<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[痒痒鼠自动刷妖气封印]]></title>
    <url>%2F2019%2F02%2F18%2Fonmyoji-support%2F</url>
    <content type="text"><![CDATA[之前在玩痒痒鼠的时候，苦于刷副本比较累，于是写了自动刷妖气封印的代码。现在对痒痒鼠兴致缺缺，在整理电脑文件的时候就把代码整理上传到了 GitHub 上了。这里记录一下整个代码的结构和思路备忘。 目录结构整个程序包含3个 Python 文件和两个目录，如下： pic : 用于放置一些用来确定场景进行比较的图片 usr : 用于放置用户名的截图 baseFunction.py : 定义了一些鼠标的基本操作 order.py : 定义了按钮位置、尺寸大小等信息；每个副本的操作流程在此 yysgo.py : 程序入口 使用 在 usr 目录下添加一张游戏名称的截图（部分截图即可，需要 png 格式）。如下图 zhzz.png（我的游戏名称是“最后之作”） ： 在命令行输入 python yysgo.py user_name what_to_do times code user_name : 你放在 usr 目录下的截图文件名，不包含格式后缀，如上面的应该是 zhzz What_to_do : 需要刷的副本，使用拼音首字母。如鬼使黑的话就是 gsh times : 需要刷的次数 code : 0~7 的数字，内容如下： &nbsp; &nbsp; 接受房主 不当房主&nbsp;&nbsp; 有活动 无活动 有活动 无活动 &nbsp;接受邀请 &nbsp;7 6&nbsp; 5&nbsp; 4&nbsp; &nbsp;不接受邀请 &nbsp;3 2&nbsp; 1&nbsp; 0&nbsp; ​ （其中的活动指的是痒痒鼠经常会有的一些鬼王活动，使得原本的「妖气封印」按钮下移一格） eg. python yysgo.py zhzz gsh 100 6 表示刷100次鬼使黑，接受悬赏封印邀请，若原房主退出则接受房主，没有特殊活动 程序内容整个程序的原理比较简单，就是模拟平时手动刷副本时的操作而已。 baseFunction.pybaseFunction.py 内定义了一些基本的鼠标操作，如： 点击 ：click(area, delay=0.5) area ：点击区域 delay ：延时最大值（后面的 delay 皆是如此） 拖拽 ：drag(begin_area, end_area, delay=0.5, duraction=0.5) begin_area ：开始区域 end_eare ：结束区域 duraction ：拖拽最大时长 寻找图片 ：find_picture(file_location)，返回 T/F file_location ：图片文件文字 以及基于这些操作的一些其他操作，如： 滚动 ：roll(block_nums, area, block_height, eps=2, delay=0.5, duraction=0.5) block_nums ：滚动格数，负数为从长往下拖拽一格，正数为从下往上 area ：可以操作的列表区域 block_height ：一格的高度 eps ：误差 检测邀请 ：check_invatation(operation, pic, button_accept, button_decline) operation ：收到悬赏封印邀请的操作 pic ：悬赏封印邀请的截图位置 button_accept ：「接受」按钮区域 button_decline ：「拒接」按钮区域 检测房主 ：check_roomowner(pic)，返回 T/F pic ：成为房主时的标志图片（默认使用亮起的「开始战斗」按钮的截图作为已经成为房主的依据） 检测等待状态 ：check_searching(pic, button)，无返回值，若不在匹配中，则点击「开始匹配」继续 pic ：正在匹配的标志图片（默认使用亮起的「取消匹配」按钮的截图作为正在匹配中的依据） 等待 ：waiting(symbol, invatation_pic, invatation_operation, roomowner_pic, searching_pic, button_set) symbol ：进入战斗（「准备」按钮亮起）的标志图片 *_pic ：上面三个检测的图片位置 invatation_operation ：收到悬赏封印邀请的操作 button_set ：按钮的位置的 list，[button_accept, button_decline, button_search] 注意 ： 图片的检测使用最原始的逐像素比对，因此若图片大小不对也会导致无法检测，这一点有兴趣的同志可以改进一下。在自行截图时要注意游戏的某些位置是动态的，或者的动态的底层上加一层半透明图片，这会导致图片检测失效。 这里与时间相关的参数都是时间的最大值，程序执行时等待的对应时间都是从0到该「最大值」的随机数，以避免防作弊检测 同理，这里所有的按钮的点击还有拖拽的操作，位置都是随机的。每一个 area（或 button） 都是 [[x1, y1], [x2, y2]] 的形式 order.pyorder.py 定义了一些组合操作（即刷一个副本的完整操作，使用 baseFunction 的函数，也可以自行在此添加其他副本的操作），设置了一些有关按钮和相关检测区域位置坐标的参数。 副本操作示例（部分内容省略）12345678910111213141516171819202122232425262728293031323334353637def guishihei(count, invitation_op, roomowner_op, user_name, activities=False): # count : 刷该副本的次数 # *_op, activities : 对应上面表格 # user_name : 用户名(与上文一致，即截图的文件名) while(count - index &gt; 0): pyautogui.moveTo(1, 1, 0.3) # 为防止鼠标的遮挡，每次需要匹配图片之前，将鼠标移动到左上角，后面不再出现这行代码 #### 执行副本组队的一连串操作 baseFunction.waiting(get_start_symbol(user_name), PIC_INVATATION, invitation_op, PIC_ROOMOWNER, PIC_IS_SEARCHING, button_set) # 若检测到 user_name.png 在屏幕中，则认为可以开始新一轮操作，否则继续等待 baseFunction.click(get_button(TEAM)) # 点击『组队』按钮 if activities: baseFunction.roll(1, get_button(AREA[0]), block_height) baseFunction.click(get_button(DEMON_SEAL)) # 点击『妖气封印』按钮，若有特殊活动，将列表下滚一格再点击 drag_area = [get_button(AREA[1][0]), get_button(AREA[1][1])] # 计算拖动区域 baseFunction.roll(8, drag_area, block_height_l2) # 下滚列表 baseFunction.click(get_button(GUI_SHI_HEI)) # 点击『鬼使黑』按钮 baseFunction.click(get_button(MATCH)) # 点击『自动匹配』 interupt = baseFunction.waiting(PIC_READY, PIC_INVATATION, invitation_op, PIC_ROOMOWNER, PIC_IS_SEARCHING, button_set) # 检测『准备』按钮是否出现 #### 特殊情况的处理 if interupt == 1: # 1 表示成为房主了(waiting()函数会每隔一段时间检测悬赏封印邀请和房间状态，正常状态返回 0) if roomowner_op: baseFunction.click(get_button(START)) # 若接受成为房主，则点击『开始战斗』按钮开始 if baseFunction.waiting(PIC_ROOMOWNER, PIC_INVATATION, invitation_op, PIC_ROOMOWNER, PIC_IS_SEARCHING, button_set) == 0: # 由于检测房主间隔时间较长，有可能执行到这里时其他玩家退出了，因此需要等待『开始战斗』按钮重新亮起 baseFunction.click(get_button(START)) baseFunction.waiting(PIC_READY, PIC_INVATATION, invitation_op, PIC_ROOMOWNER, PIC_IS_SEARCHING, button_set) # 等待『准备』按钮 else: baseFunction.click(get_button(BACK)) # 若不接受房主，左上角返回，开始下一轮 countinue #### 到这里准备按钮亮起，玩家已经进入副本并可以开始战斗了 baseFunction.click(get_button(PREPARE)) # 点击『准备』按钮 #### 战斗完成，点击任意位置退出 baseFunction.waiting(PIC_FINISH, PIC_INVATATION, invitation_op, PIC_ROOMOWNER, PIC_IS_SEARCHING, button_set) baseFunction.click(get_button(FINISH)) 部分参数设置(分辨率等参数不同，最好使用前重新测定坐标） block_height_l1/l2 : 列表一格的高度，我在测量时 妖气封印的子列表(l2) 和其本身的列表(l1) 高度并不一样 BASE : 基准点，后面的所有坐标都是对此坐标的相对位置，采取窗口左上角坐标作为基准点 ACCEPT, DECLINE, BACK, START : （悬赏封印）接受/拒绝，返回，开始战斗 按钮的位置 MATCH, PREPARE, FINISH : 自动匹配，准备，完成（点击任意位置退出） 按钮的位置 TEAM, DEMON_SEAL : 组队（庭院界面），妖气封印 按钮的位置 AREA : 列表的区域，roll() 函数需要这个区域来确定拖动的界限，AREA[0]是点击组队后出现的列表(l1)，AREA[1]是妖气封印下的子列表(l2) PIC_*, USER_BASE : 各种图片位置，用户名截图目录 yysgo.py程序入口，不用多说。 在 order.py 中添加新的操作后，需要在这里调用。 备注 图片检测的速度不够快，这有时会导致一些意料之外的事发生 逐一像素检测图片会导致以后若有改版，需要重新截图 order.py 中对特殊状况的处理似乎有一些错误，不过在实际使用中没有发生意外，就没有修改了st=>start: 开始 cond1=>condition: 处于主界面？ cond2=>condition: 「准备」按钮亮起？ cond3=>condition: 检测战斗是否完成 cond4=>condition: 是否达到设定次数 op1=>operation: 「组队」->「妖气封印」->「对应副本」->「自动匹配」 op5=>operation: 「准备」 op6=>operation: 空白处任意点击 e=>end: 结束 st->cond1 cond1(yes)->op1 cond1(no)->cond1 op1->cond2 cond2(yes)->op5 cond2(no)->cond2 op5->cond3 cond3(yes)->op6 cond3(no)->cond3 op6(right)->cond4 cond4(yes)->e cond4(no)->cond1{"scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12} var code = document.getElementById("flowchart-0-code").value; var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-0-options").value)); var diagram = flowchart.parse(code); diagram.drawSVG("flowchart-0", options);]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用 dlib 对人脸特征点标记]]></title>
    <url>%2F2018%2F02%2F24%2Fface-landmark-with-dlib68%2F</url>
    <content type="text"><![CDATA[我在做表情识别的时候，使用的是 CK/CK+ 的数据集，然而令人难受的是，我一直不知道如何去标记人脸特征点。因为数据集里面有标记好的 Landmarks，都放在里面了。所以我训练是直接用这个数据的，测试集其实也是从里面随机抽取的。 然而昨天在找资料的时候，我很敏感的发现了68这个数字。天哪，我怎么会忘记，这个就是 CK/CK+ 数据集里面标记点的个数啊！ 于是，我开始了 dlib 的调试。 配置话不多说，还是： macOS + anaconda + Python2.7 dlib 的安装：对于 Mac 用户，参见这一篇 其实我根本就是忘记了我在安装 face_recognition 时曾经在 Python3 的环境下安装过 dlib 了。看这里 特征检测器需要下载特征检测器，当然你也可以自己训练 (/滑稽) 下载后可以解压出一个 dat 文件，我们需要的就是这个。 检测人脸之前就说过，dlib 也是可以检测人脸的。 12detector = dlib.get_frontal_face_detector()faces = detector(img, 1) 这样，faces 里面就存储了所有脸部区域的范围。 值得注意的是，faces[i] 是第 i 张脸，使用.top() .bottom() .left() .right()四个函数得到具体的值 特征点标记加载刚刚下载的文件来标记特征点。 12landmark_predictor = dlib.shape_predictor('./shape_predictor_68_face_landmarks.dat')shape = landmark_predictor(img,face_area) 其中，shape 就保存了特征点的信息。 为了得到特征点的坐标，需要使用.part()函数，如下: 12x[i] = shape.part(i).xy[i] = shape.part(i).y 特征点是有顺序的，如下图： 68个特征点的位置如下： 12345678910&#123; IdxRange jaw; // [0 , 16] IdxRange rightBrow; // [17, 21] IdxRange leftBrow; // [22, 26] IdxRange nose; // [27, 35] IdxRange rightEye; // [36, 41] IdxRange leftEye; // [42, 47] IdxRange mouth; // [48, 59] IdxRange mouth2; // [60, 67]&#125; 实战1234567891011121314151617181920# -*- coding:utf-8 -*-import cv2import dlibdetector = dlib.get_frontal_face_detector()landmark_predictor = dlib.shape_predictor('./shape_predictor_68_face_landmarks.dat')img = cv2.imread('./lyf2.png')faces = detector(img, 1)if (len(faces) &gt; 0): for k,d in enumerate(faces): # cv2.rectangle(img,(d.left(),d.top()),(d.right(),d.bottom()),(255,255,255)) shape = landmark_predictor(img,d) for i in range(68): img2 = cv2.circle(img, (shape.part(i).x, shape.part(i).y),5,(0,255,0), -1, 8) img2 = cv2.putText(img,str(i),(shape.part(i).x,shape.part(i).y),cv2.FONT_HERSHEY_SIMPLEX,0.5,(255,2555,255))cv2.imshow('Frame',img)cv2.imwrite('./landmark.jpg', img2)cv2.waitKey(0) 效果如下： 蛤，你问 Landmark 还可以用来干嘛？ 当然是让美帝也感受一下膜法的力量！！！ 根据眼睛眉毛附近的点，来设计黑框眼镜的位置和大小。 代码很简单，我就不放了]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>Python</tag>
        <tag>人脸识别</tag>
        <tag>情感识别</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用 OpenCV 检测人脸]]></title>
    <url>%2F2018%2F02%2F24%2FFace-recog-with-opencv%2F</url>
    <content type="text"><![CDATA[在做表情识别的时候，突然在《机器学习——算法原理与编程实践》一书中看到了人脸检测的部分。书中使用的是 OpenCV 自带的 Haar 特征级联表作为训练集，标记人脸的。这种方法我之前也在网上看到过，因为没有成功（现在看来应该是使用了错误的表造成的）所以使用了 face_recognition 的库来进行的。 现在既然成功完成了这种方法，那自然也要用起来。 前期配置这一次的表情识别的前期工作都是用 Python2.7 做的，因此代码也是基于 Python2.7 的。Python3 的话，应该也是大同小异的。 建议使用 anaconda 配置 Python 虚拟环境，使用起来也很方便。 需要使用的特征级联表，书上使用 haarcascade_frontalface_alt_tree.xml 和 lbpcascade_frontalface.xml，我将使用后者。 上述两个文件分别在链接位置 haarcascades 和 lbpcascades 目录下。 使用方法关键代码123456789face_cascade = cv2.CascadeClassifier('./lbpcascade_frontalface.xml')# 参数说明：# gray：传入的图片，一般使用灰度图# 1.2： scaleFactor--表示在前后两次相继的扫描中，搜索窗口的比例系数。默认为1.1：即每次搜索窗口依次扩大10%# 3： minNeighbors--表示构成检测目标的相邻矩形的最小个数(默认为3个)。# 如果组成检测目标的小矩形的个数和小于 min_neighbors - 1 都会被排除。# 如果min_neighbors 为 0, 则函数不做任何操作就返回所有的被检候选矩形框，# 这种设定值一般用在用户自定义对检测结果的组合程序上faces = face_cascade.detectMultiScale(gray, 1.2, 3) 完整代码12345678910111213141516171819202122# -*- coding: utf-8 -*-from numpy import *import cv2face_cascade = cv2.CascadeClassifier('./lbpcascade_frontalface.xml')img = cv2.imread('./test.jpg')gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)faces = face_cascade.detectMultiScale(gray, 1.2, 3)for (x, y, w, h) in faces: img2 = cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 1) cv2.imwrite('./sample.jpg',img2) # 下面是面部区域的灰度图和原图，可以使用 imwrite 保存为文件 roi_gray = gray[y: y + h, x: x + w] roi_color = img[y: y + h, x: x + w]cv2.imshow('img', img)cv2.waitKey(0)cv2.destroyAllWindows() 效果图 P.S. 在使用 dlib 做面部特征点标记的时候，发现 dlib 也有 face_detector，有时间我会在下一篇文章中介绍一下。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>Python</tag>
        <tag>人脸识别</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Face Recognition的配置和初步使用]]></title>
    <url>%2F2018%2F01%2F19%2FFace-Recognition%2F</url>
    <content type="text"><![CDATA[由于新一届的物联网大赛有关于人脸识别的部分，因此老师让我给学弟学妹讲一讲有关人脸识别的部分。因为上次刷知乎的时候看到了一个圣诞节时的微信头像自动带圣诞帽的小程序用到了这个 face_recognition 的 Python 库，上网查了一下，发现离线识别率高达99.38%，因此就打算使用这个库了。 理想很丰满，现实很骨感。折腾了很长时间，不由得感叹，这个库是真 TMD 难配。 以下就是记录的一些过程吧！ 配置和安装需要的诸如 numpy、opencv 等的机器学习的常用库就不写了，这些不难，而且我早已配过了。重点是安装 dlib. 本次的配置基本参考face_recognition的 readme 需求： Python 3.3+ or Python 2.7 macOS or Linux (Windows not officially supported, but might work) 这里我使用的环境就是 Python3.6 + macOS，（作者已经说了，Windows 环境下没有测试，而且我看了网上好像 Windows 确实各种坑，所以小伙伴们还是不要去跳坑了吧，老老实实 Linux 吧） 安装 dlib作者有给连接指导怎样安装 dlib 的，How to install dlib from source on macOS or Ubuntu，但是这个网址被墙了，可以科学上网的同学就直接去看。 为了帮助无法科学上网的同学，我把 dlib 安装指导 copy 了过来： 前置工作： For macOS 安装 XCode （主要是 XCode command line utils） 安装 homebrew brew install boost-python --with-python3 --without-python For Linux sudo apt-get install libboost-all-dev 安装： clone the code from githubgit clone https://github.com/davisking/dlib.git build the main dlib librarycd dlibmkdir build; cd build; cmake .. -DDLIB_USE_CUDA=0 -DUSE_AVZ_INSTRUCTIONS=1; cmake --build build and install the python extensionscd ..python3 setup.py install --yes USE_AVX_INSTRUCTIONS --no DLIB_USE_CUDA 安装 face_recognition这个就没什么好说的了，pip3 install face_recognition 测试如果你进入 Python3，可以成功 import dlib ，就表示你的 dlib 成功安装了如果你在 terminal 内输入 face_ ，按 tab 键，能够自动补全 face_recognition 说明 face_recognition 已经成功安装了 备注作者提供了一个 virtualBox 的 Ubuntu 镜像，内部已经配置好了一切的环境，如果有需要可以点这里下载 直接使用前面在 terminal 里面，face_recognition 就已经可以直接使用了，具体的做法是： 1face_recognition 已知人物照片的目录 需要识别的照片目录 还可以加入一些参数，比如容忍度 --tolerance ，越小的容忍度，则识别时就越严格 加入 --show-distance true 可以显示两个人脸的差距，用于调整容忍度 代码前面的是直接使用 face_recognition 这个命令的，当然也可以在 Python 里面 import 这个库，做其他的处理 我在使用库的时候遇到了 No module named &#39;face_recognition&#39; 的问题，如果你也遇到了这个问题，并且你确定你在输入 pip3 list 后，face_recognition 这个库确实已经安装完成了。那么你可以在代码中加入下面两句以引用 face_recognition 12import syssys.path.append("/usr/local/lib/python3.6/site-packages/") 在添加了正确的路径之后，就可以正确的 import 这个包了（每个人的 site-packages 的位置不一定一样） 面部定位123image = face_recognition.load_image_file("./pic/obm2.jpg")face_locations = face_recognition.face_locations(image)print(face_locations) 首先使用 load_image_file 函数将需要识别的图片添加进去，再调用 face_locations 函数就可以返回面部的坐标，如下： 1[(1268, 2884, 1423, 2729), (1062, 2248, 1216, 2093), (1142, 2575, 1271, 2446), (1200, 1543, 1329, 1414), (1295, 3111, 1481, 2925), (1062, 2764, 1216, 2609), (1027, 3482, 1212, 3296), (1013, 1199, 1142, 1070), (1148, 1336, 1302, 1182), (1182, 1044, 1337, 889), (956, 1629, 1085, 1500), (1212, 778, 1398, 593), (1062, 1869, 1216, 1715), (956, 2532, 1085, 2403), (1406, 3510, 1628, 3287)] 其中，每一个脸部位置坐标是由4个数字的元组组成的，其分别为 $ x_1 , y_1 , x_2 , y_2 $ ，这两个点分别是确定脸部位置的两角，可以用 OpenCV 加载图片，并且使用切片操作截取脸部 123456index = 0for (x1, y1, x2, y2) in face_locations : print(x1, x2, y1, y2) f = img[x1 : x2, y2 : y1] index = index + 1 cv2.imwrite("hezhao_" + str(index) + ".jpg", f) 面部比较 加载已知的头像 123dt_image = face_recognition.load_image_file("./head/dt_1.jpg")sll_image = face_recognition.load_image_file("./head/sll_1.jpg")obm_image = face_recognition.load_image_file("./head/obm_1.jpg") 加载待识别的头像 1unknown_image_1 = face_recognition.load_image_file("./unknow_head/unknow_1.jpg") 编码 12345dt_encoding = face_recognition.face_encodings(dt_image)[0]sll_encoding = face_recognition.face_encodings(sll_image)[0]obm_encoding = face_recognition.face_encodings(obm_image)[0]unknown_encoding = face_recognition.face_encodings(unknown_image_1)[0] 输入结果 1results = face_recognition.compare_faces([dt_encoding, sll_encoding, obm_encoding], unknown_encoding[i]) 输出的结果是一个3个的 list，内部的值分别是 true 或者 false 表示是不是对应的人]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>Python</tag>
        <tag>人脸识别</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2017%2F02%2F11%2Fhello-world%2F</url>
    <content type="text"><![CDATA[写在前面由于重装系统的缘故，Github也是很久都没有使用过了（并不是因为我懒得写代码 /手动滑稽）。 由于今天突然想使用Github和用Hexo写博客了，因此花了些时间把东西弄起来了（很坑的东西是我以前配置Hexo时参考的博客居然404了，因此又重新找了好久，我在考虑着是不是应该自己写一个教程，方便以后参考） 我之前是有个spectop1017的Github账号的，这是因为我当时学习使用Github时不太会，也不知道怎么的申请了两个账号，也不知道怎么的使用了spectop1017这个账号去提交代码了。那个账号里面也没有什么东西了，基本上都是当时学习Android时一些练手的程序，在spectop1017.github.io上面写的一些博客我也搬到spectop.github.io这里了，那个账号就不打算再使用了。另外我在一大堆文件中居然找到了当时因为重装系统而丢失的第一批Blog的Markdown文件，真是意外之喜，就一起搬运过来了。 分割线：以下是Hexo自带的Hello world文档 Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
      <categories>
        <category>杂项</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[markdown文档中mathjax的问题]]></title>
    <url>%2F2016%2F01%2F29%2Fmarkdown%E6%96%87%E6%A1%A3%E4%B8%ADmathjax%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[在写markdown文档时经常会需要插入数学公式，我之前只会使用图片插入，上次在看到mathjax后，我开始了使用mathjax的历程，但在实际写文档的过程中遇到了一些问题。 关于有一些公式无法正确的显示在写机器学习的文章中遇到的一个关于范数的公式写出来编辑器上显示没有问题，但是一旦放进文档里就不行了，这个问题困扰了我很长时间。 这是代码：12&gt; 严格意义上讲，Minkowski Distance 不是一种距离，而是一组距离的定义&gt; $$ \lim_&#123;k\to\infty&#125;\left( \sum_&#123;i=1&#125;^n\mid p_i-q_i\mid ^k\right)^\frac&#123;1&#125;&#123;k&#125; $$ 这是效果： 严格意义上讲，Minkowski Distance 不是一种距离，而是一组距离的定义$$ \lim{k\to\infty}\left( \sum{i=1}^n\mid p_i-q_i\mid ^k\right)^\frac{1}{k} $$ 这里haroopad显示的公式是正确的，但是hexo编译过后的网页显示就不对了。 把代码剪裁一下，看看什么样子的公式是可以的：12&gt; 严格意义上讲，Minkowski Distance 不是一种距离，而是一组距离的定义&gt; $$ \lim_&#123;k\to\infty&#125;\left( \sum_i \right) $$ 效果： 严格意义上讲，Minkowski Distance 不是一种距离，而是一组距离的定义$$ \lim_{k\to\infty}\left( \sum_i \right) $$ 这个好像就可以，但是貌似sum后面的i一旦加上花括号就不行：12&gt; 严格意义上讲，Minkowski Distance 不是一种距离，而是一组距离的定义&gt; $$ \lim_&#123;k\to\infty&#125;\left( \sum_&#123;i&#125; \right) $$ 效果： 严格意义上讲，Minkowski Distance 不是一种距离，而是一组距离的定义$$ \lim{k\to\infty}\left( \sum{i} \right) $$ 于是我点开了两个网页的源代码，定位到这一行：1&lt;p&gt;严格意义上讲，Minkowski Distance 不是一种距离，而是一组距离的定义&lt;br&gt;$$ \lim&lt;em&gt;&#123;k\to\infty&#125;\left( \sum&lt;/em&gt;&#123;i&#125; \right) $$&lt;/p&gt; 1&lt;p&gt;严格意义上讲，Minkowski Distance 不是一种距离，而是一组距离的定义&lt;br&gt;$$ \lim_&#123;k\to\infty&#125;\left( \sum_i \right) $$&lt;/p&gt; 可以发现最明显的不同就算lim后面的 &lt;em&gt;，这时我们注意到，hexo在编译的时候将lim和sum后面的下划线 _翻译成强调的 &lt;em&gt; 了，仔细观察前面的公式，确实可以发现一部分变成了斜体。所以我们要在所有的下划线 _ 前面加上 \ 转义就可以了。 OK，搞定 p.s 我的chrome上显示的公式后面都有一个竖线，firefox没有，内啥，一般平时用chrome习惯，所以有人知道怎么弄咩？ 上面的问题在重新配置Hexo之后就没有了，个人觉得应该是版本的问题？]]></content>
      <categories>
        <category>Markdown</category>
      </categories>
      <tags>
        <tag>Markdown</tag>
        <tag>MathJax</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[「学习笔记」机器学习(1)]]></title>
    <url>%2F2016%2F01%2F22%2F%E3%80%8C%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E3%80%8D%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-1%2F</url>
    <content type="text"><![CDATA[科学算法库的安装(linux) 1.安装Numpysudo apt-get install python-numpy 2.安装Scipysudo apt-get install python-numpy 3.Matplotlibsudo apt-get install tk-dev sudo apt-get install python-gtk2-dev sudo apt-get install python-pyside 4.spyder GUI环境sudo apt-get install spyder 上述安装完毕后，可以利用 1234567891011#! /usr/bin/pythonimport numpy as npimport matplotlib.pyplot as pltx = np.linspace(0,4*3.1415,100)y = np.sin(x)plt.figure(figsize=(8,4))plt.plot(x,y,label="$sin(x)$",color="red",linewidth=2)plt.legend()plt.show() 进行测试。若生成正弦曲线窗口，则配置完成. NumPy的基本操作 Numpy 的导入import numpy as np 这种写法在使用相关函数的时候需要写明是哪个包的，如: myZero = np.zeros([3,5]) 还可以导入包全局使用 from numpy import * NumPy 的基本操作 创建全0矩阵和全1矩阵 12myZero = zeros([n,m])myOne = ones([n,m]) 生成随机矩阵 1myRand = random.rand(n,m) # n 行 m 列的 0～1 之间的随机数矩阵 生成单位矩阵 1myEye = eye(n) # n * n 的单位阵 将一个数组转化为一个矩阵 1myMatrix = mat([[1,2,3],[4,5,6],[7,8,9]]) 矩阵所有元素求和 1S = sum(myMatrix) 矩阵各元素的乘积 1matrix = multiply(matrix1, matrix2) # matrix1 和 matrix2 对应元素相乘的矩阵 求矩阵的 n 次幂 1matrix = power(myMatrix, n) #生成一个矩阵，矩阵内部的元素是原矩阵对应元素的n次幂 矩阵的转置 12print matrix.T #打印转置后的矩阵，不改变原矩阵matrix.transpose() #同上 矩阵的其他操作 1234567[m, n] = shape(matrix) # m, n为矩阵的行列数myscl1 = matrix[0] # 矩阵的切片操作，取第一行myscl2 = matrix.T[0] # 矩阵的切片操作，取第一列mycpmat = matrix.copy() # 矩阵的复制print matrix1 &lt; matrix2 # 矩阵的比较，会逐一比较对应的每一个元素，并输出一个仅包含True, False 的相同大小的矩阵dot(m1,m2) #计算m1,m2的点积norm(v) #计算向量V的范数 Linalg线性代数库 矩阵的行列式 1print linalg.det(matrix) 矩阵的逆 1print linalg.inv(matrix) 矩阵的对称 1print matrix * matrix.T 矩阵的秩 1print linalg.matrix_rank(A) 可逆矩阵求解 1print linalg.solve(A,b.T) # 如果b已经是一列的就不用转置了 各类距离的python实现 各类距离会在后面说明 Euclidean Distance 123vector1 = mat([1,2,3])vector2 = mat([4,5,6])print sqrt((vector1-vector2)*(vector1-vector2).T) Manhattan Distance 123vector1 = mat([1,2,3])vector2 = mat([4,5,6])print sum(abs(vector1-vector2)) Chebyshev Distance 123vector1 = mat([1,2,3])vector2 = mat([4,5,6])print abs(vector1-vector2).max() Cosine 12cosV12 = dot(vector1,vector2)/(linalg.norm(vector1)*linalg.norm(vector2))print cosV12 Hamming Distance 123matV = mat([[1,1,0,1,0,1,0,0,1], [0,1,1,0,0,0,1,1,1]])smstr = nonzero(matV[0] - matV[1]);print shape(smstr[0])[1] Jaccard Distance 123import scipy.spatial.distance as distmatV = mat([[1,1,0,1,0,1,0,0,1], [0,1,1,0,0,0,1,1,1]])print dist.pdist(matV, 'jaccard') 机器学习的数学基础 范数 向量的范数可以简单、形象的理解为向量的长度，或者向量到坐标系原点的距离，或者相应空间内的两点之间的距离 向量的范数定义 : 向量的范数是一个函数 $ \parallel x\parallel $ ,满足非负性 $ \parallel x\parallel &gt; 0 $ , 齐次性 $ \parallel cx\parallel = \mid c\mid\parallel x\parallel $ ,三角不等式 $ \parallel x+y\parallel \leq\parallel x\parallel +\parallel y\parallel $ 。 L1范数： $\parallel x\parallel $为 $ x $向量各个元素绝对值之和。L2范数： $\parallel x\parallel $为 $ x $向量各个元素平方和的开方，又称 Euclidean 范数或者 Frobenius 范数。Lp范数： $\parallel x\parallel $为 $ x $向量各个元素绝对值 $ p $次方和的 $ 1\over p $ 次方L $\infty $范数： $\parallel x\parallel $为 $ x $向量各个元素绝对值最大的那个元素，如下：$$ \lim_{k\to\infty}\left( \sum_{i=1}^n\mid p_i-q_i\mid ^k\right)^\frac{1}{k}$$ Minkowski Distance (闵可夫斯基距离) 严格意义上讲，Minkowski Distance 不是一种距离，而是一组距离的定义。两个n维向量 $ A(x_{11},x_{12},\cdots,x_{1n}) $ 与 $ B(x_{21},x_{22},\cdots,x_{2n}) $ 间的Minkowski距离定义为：$$ d_{12}=\sqrt[p]{\sum_{k=1}^n(x_{1k}-x_{2k})^p} $$其中p是一个变参数。 当 p=1 时，就是 Manhattan Distance (曼哈顿距离) 当 p=2 时，就是 Euclidean Distance (欧氏距离) 当 $ p\to\infty $ 时，就是 Chebyshev Distance (切比雪夫距离) Euclideam Distance 欧氏距离（L2范数）是最易于理解的一种距离计算方法，源于欧氏空间的两点距离公式两个n维向量 $ A(x_{11},x_{12},\cdots,x_{1n}) $ 与 $ B(x_{21},x_{22},\cdots,x_{2n}) $ 之间的欧氏距离：$$ d_{12}=\sqrt{\sum_{k=1}^n(x_{1k}-x_{2k})^2} $$表示为向量运算的形式：$$ d_{12}=\sqrt{(A - B)(A - B)^T} $$ Manhattan Distance 曼哈顿距离（L1范数）可以理解为计算网格中两点路径的距离二维平面两点 $ A(x_1,y_1) $ 和 $ B(x_2,y_2) $ 间的曼哈顿距离:$$ d_{12}=\mid x_1-x_2\mid +\mid y_1-y_2\mid $$两个n维向量 $ A(x_{11},x_{12},\cdots,x_{1n}) $ 与 $ B(x_{21},x_{22},\cdots,x_{2n}) $ 之间的曼哈顿距离：$$ d_{12}=\sum_{k=1}^n\mid x_{1k}-x_{2k}\mid $$ Chebyshev Distance 切比雪夫距离类似与棋盘上国王从一点到另一点移动的最少次数，即 $ max(\mid x_1-x_2\mid,\mid y_1-y_2\mid) $两个n维向量 $ A(x_{11},x_{12},\cdots,x_{1n}) $ 与 $ B(x_{21},x_{22},\cdots,x_{2n}) $ 之间的切比雪夫距离：$$ d_{12}=max_i(\mid x_{1i}-x_{2i}\mid) $$该公式的另一个等价公式：$$ d_{12}=\lim_{k\to\infty}\left(\sum_{i=1}^n\mid x_{1i}-x_{2i}\mid^k\right)^\frac{1}{k} $$ Cosine 夹角余弦可以用来两个向量方向的差异，机器学习中借用这一概念来衡量样本之间的差异两个n维向量 $ A(x_{11},x_{12},\cdots,x_{1n}) $ 与 $ B(x_{21},x_{22},\cdots,x_{2n}) $ 之间的夹角余弦：$$ \cos\theta=\frac{AB}{\mid A\mid\mid B\mid} $$即：$$ \cos\theta=\frac{\sum_{k=1}^nx_{1k}x_{2k}}{\sqrt{\sum_{k=1}^nx_{1k}^2}\sqrt{\sum_{k=1}^nx_{2k}^2}} $$ Hamming Distance 汉明距离的定义：两个等长字符串s1,s2,将其中一个变成另一个需要的最小替换次数。应用：信息编码（为了增强容错性，应使得编码间的最小汉明距离尽可能大） Jaccard Similarity Coefficient(杰卡德相似系数) 杰卡德相似系数：两个集合A,B的交集元素在并集元素中所占的比例，用符号 $ J(A,B) $ 表示$$ J(A,B)=\frac{\mid A\cap B\mid}{\mid A\cup B\mid} $$杰卡德距：与杰卡德相似系数相反的概念：$$ J_\delta(A,B)=1-J(A,B)=\frac{\mid A\cup B\mid-\mid A\cap B\mid}{\mid A\cup B\mid} $$ 特征间的相关性 相关系数与相关距离 相关系数： $$ \rho_{XY}=\frac{Cov(X,Y)}{\sqrt{D(X)}\sqrt{D(Y)}}=\frac{E((X-EX)(Y-EY))}{\sqrt{D(X)}\sqrt{D(Y)}} $$ 相关距离： $$ D_{XY}=1-\rho_{XY} $$python实现： 12345678910featuremat = mat(...) # 初始化矩阵# 计算均值mv1 = mean(featuremat[0]) # 计算第一列的均值mv2 = mean(featuremat[1]) # 计算第二列的均值#计算两列的标准差dv1 = std(featuremat[0]) dv2 = std(featuremat[1])corref = mean(multiply(featuremat[0]-mv1,featuremat[1]-mv2))/(dv1*dv2)print corref #输出相关系数print corrcoef(featuremat) #输出相关系数矩阵 马氏距离]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[重写博客]]></title>
    <url>%2F2016%2F01%2F22%2F%E9%87%8D%E5%86%99%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[一件很不幸的事，我重装系统的时候好像忘了把hexo的文章备份下来，结果那些markdown文档就都呵呵了 TAT～ 重新配置了一次hexo真的好麻烦，搞了半天，我真不知道我当时是怎么弄好的！ 之前的那些文章我还没有md文档，不过我倒是把整个博客给clone下来保存好了，以后如果有时间还是会恢复的吧。 这么快就放假了，然而真心觉得2015有点对不起自己，对不起这一年的时间。不过怎么说呢，后悔是没有用的，毕竟人要往前看嘛。只是希望2016结束的时候我不要还是这样，还是说出同样的话。 再不努力就老了！]]></content>
      <categories>
        <category>杂项</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[背包九讲]]></title>
    <url>%2F2015%2F07%2F21%2F%E8%83%8C%E5%8C%85%E4%B9%9D%E8%AE%B2%2F</url>
    <content type="text"><![CDATA[0/1背包问题 有N件物品和一个容量为V的背包。放入第i件物品耗费的空间是Ci，得到的价值是Wi。求解将哪些物品装入背包可使价值总和最大？ 将每一件物品从1到n编号，从第1件物品开始，每一件物品就只有两个状态：放进背包了 / 没有放进背包。 我们画一张表格，行对应着每一件物品，列对应着背包的重量，那么pack[i][j]就表示 前i件物品，背包最大承重j 这个子问题的解。 给一组数据作为样例： 5 10 6 2 3 2 5 6 4 5 6 4 第一行表示有5件物品，10为最大承重，2-6行为5个物品的价值和重量。 生成以下的表格 0 6 6 6 6 6 6 6 6 6 0 6 6 9 9 9 9 9 9 9 0 6 6 9 9 9 9 11 11 14 0 6 6 9 9 9 10 11 13 14 0 6 6 9 9 12 12 15 15 15 所以最终的结果是最后一行最后一列的 15 给出代码： 12345678910111213141516171819202122232425262728293031/* 01 package problem */#include &lt;iostream&gt;#include &lt;algorithm&gt;#include &lt;cstring&gt;using namespace std;int pack[100][1000];int c[100],w[100];void make(int n, int r)&#123; memset(pack,0,sizeof(pack)); for (int i = 1; i &lt;= n; i++) for (int j = w[i]; j &lt;= r; j++) pack[i][j] = max(pack[i - 1][j - c[i]] + w[i], pack[i - 1][j]); cout&lt;&lt;pack[n][r];&#125;int main()&#123; int t,n,V; cin&gt;&gt;t; while(t--)&#123; //多组数据 cin&gt;&gt;n&gt;&gt;V; for (int i = 1; i &lt;= n; i++) cin&gt;&gt;c[i]&gt;&gt;w[i]; make(n,V); &#125; return 0;&#125; 代码优化 这个代码在时间上应该已经不能再优化了，但是还可以考虑空间复杂度的优化。 优化的基本思路： 考虑所用到的状态转移方程: pack[i][j] = max(pack[i-1][j-c[i]] + w[i], pack[i-1][j]); 可以发现 pack[i][j] 的值并不和整个二维表的每一个数字的值都有关，而是仅仅和上面一行的值有关，所以可以使用 pack[2][n] 这么大的数组来存储结果。 考虑状态转移方程的实际情况，还可以使用一维数组来进行运算，但是要注意的是，此时，循环应该从后往前进行。因为如果是按从前往后的顺序，那么 pack[i][j] = max(pack[i][j-c[i]] + w[i] , pack[i][j]); 中进行比较的两个值 pack[i][j] 是没有更新的，也就是 pack[i-1][j] 的值，而 pack[i][j - c[i]]一定是前面被更新过的，也就是 pack[i][j-w[i]] 的值。这就是说，max() 比较的两个数是属于原来二维数组中不同的两行，而不是我们期望的相同的两行。 如果上面的说法不能理解我们不妨这样：有一件物品的性价比很高，在pack数组的某个位置，我们第一次将这个物品放入背包中，但是按照从前往后的顺序，很可能在这个位置的后面某个位置我们会再次将这个物品添加进去。 优化后的代码 12345678910111213141516171819202122232425#include &lt;iostream&gt;#include &lt;cstring&gt;using namespace std;int pack[10000],c[1000],w[1000];void make(int n, int r)&#123; memset(pack,0,sizeof(pack)); for (int i = 1; i &lt;= n; i++) for (int j = r; j &gt;= w[i]; j--) pack[j] = max(pack[j], pack[j - c[i]] + w[i]); cout&lt;&lt;pack[r]&lt;&lt;endl;&#125;int main()&#123; int n,t,V; cin&gt;&gt;t; while(t--)&#123; cin&gt;&gt;n&gt;&gt;V; for (int i = 1; i &lt;= n; i++) cin&gt;&gt;c[i]&gt;&gt;w[i]; make(n,V); &#125; return 0;&#125; 初始化问题： 如果限定背包必须装满，那么需要将数组初始化为 -∞ （负无穷大） 如果背包可以不装满，那么数组初始化为0 为了后面的书写方便，我们把代码改成这样1234void ZeroOnePack(int c,int w)&#123; for (int i = V; i &gt;= c; i--) pack[i] = max(pack[i], pack[i - c] + w);&#125; 这样01背包问题的主要代码就是这样： 12for (int i = 0; i &lt; n; i++) ZeroOnePack(c[i],w[i]); 这样ZeroOnePack()这个函数就专门解决了“放一个物品”的问题 完全背包问题 完全背包问题和0/1背包问题几乎一模一样，不同的就是物品不再是一个，而是无数个 思路 完全背包不同处是原来的一个物品变成了无数个，但是我们还是可以把它变成0/1背包问题的，试想一下，即使拥有无数个物品，但是真的可以用无数个吗？ 不可能，因为背包的容量有限，所以每个物品c,w最多可以使用[V/c]个，所以以下面的数据为例： c: 3 2 5 4 w: 7 4 2 5 V = 10 我们完全可以把这组数据改成这样： c: 3 3 3 2 2 2 2 2 5 5 4 4 w: 7 7 7 4 4 4 4 4 2 2 5 5 原因自然是背包容量最大为10,所以占用空间为3的物品最多放3个，修改过后的数据就可以用0/1背包的方法处理 那难道完全背包需要重开一个c2[],w2[]，然后按0/1背包处理吗？ 当然不是，还记得我们将0/1背包进行优化时说的如果循环从前向后进行会发生什么后果吗？ 这一句 “但是按照从前往后的顺序，很可能在这个位置的后面某个位置我们会再次将这个物品添加进去。” 看到了？0/1背包时为了避免重复，我们将循环改为从后往前，但是完全背包是可以重复使用物品的，对吧？所以代码： 1234void CompletePack(c,w)&#123; for (int i = c; i &lt;= V; i++) pack[i] = max(pack[i],pack[i - c] + w )&#125; 怎么样，和0/1背包只有一点点的差别对不对？ 3.多重背包问题 多重背包和0/1背包不同的地方就是物品不是一个而是有m个 所以我们还是就一个物品c,w,m分析： 对于m可能有两种情况： m &gt;= [V/c]，这种情况明显是完全背包 0 &lt; m &lt; [v/c]，对于这种情况需要认真分析一下 我们仍然需要按照0/1背包的思路把这些物品拆开，而且我们要保证我们拆出来的这些物品可以通过组合表示出1到m任意件物。 我们可以考虑二进制的计数方法，这样我们把物品拆成(c,w) , (2c,2w) , (4c,4w) …… [(m-2^k)*c , (m-2^k)*w)] 不管最优解会在这件物品中取几件，我们都可以用我们拆出来的这些物品来表示（请自己证明，二进制的思想） 所以，有了思路，代码就简单了： 12345678910111213void MultiplePack(c,w,m)&#123; if (c * m &gt;= V) &#123; CompletePack(c,w); return; &#125; k = 1; while (k &lt; m) &#123; ZeroOnePack(c*k,w*k); m = m - k; k = 2 * k; &#125; ZeroOnePack(c * m, w * m);&#125; 其实就是0/1背包和完全背包的组合，有木有？ 未完待续……]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
        <tag>背包问题</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下如何实现C语言的system("pause")]]></title>
    <url>%2F2015%2F04%2F15%2FLinux%E4%B8%8B%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0C%E8%AF%AD%E8%A8%80%E7%9A%84system-pause%2F</url>
    <content type="text"><![CDATA[getch() ? 不是标准库中的函数，在Linux中一般情况无法使用 getchar() + printf(“\b”) ? 貌似使用getchar()读入，再输出一个退格符将原来回显的字符删除应该是可以的，但是在实际试了一下发现根本不行。。。 原因：终端驱动器确实会读一个字符，但是他的输入只有到’\n’ 或 EOF 才会结束，所以如果不输入回车就不会实际执行getchar(). 当然，如果上一次输入的字符并没有全部读完是可以getchar()把没有读完的字符读掉。 解决办法123456789void system_pause(void)&#123; getchar(); puts("Press any key to continue..."); system("stty raw"); getchar(); system("stty cooked"); printf("\b");&#125; 这段代码也是我在网上找到的，我的理解是： getchar()读掉上面多余的’\n’，按程序的实际情况添加 输出”Press any key to continue…” system(“stty raw”);：将终端驱动器改为一次一个字符的模式，即输入一个字符就结束输入 getchar(); 读一个字符 system(“stty cooked”); 将终端驱动器改回一次一行的模式 printf(‘\b’); 退格，将回显的字符删除 p.s. 以上仅仅是个人理解，欢迎大家指出其中的错误]]></content>
      <categories>
        <category>C/C++</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C/C++的一些有趣的区别]]></title>
    <url>%2F2015%2F03%2F17%2FC-C%2B%2B%E7%9A%84%E4%B8%80%E4%BA%9B%E6%9C%89%E8%B6%A3%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[在geeksforgeeks上看到一篇文章，说的是一些在C中可以编译但在C++中不行的程序，觉得比较好玩，就翻译分享一下啦。 在C++中，在main()中使用其它自定义的函数时必须在前面写上声明或者定义，但是在C中却可以写在main()的后面 123456789101112#include&lt;stdio.h&gt;int main()&#123; foo(); // foo() is called before its declaration/definition return 0;&#125; int foo()&#123; printf("Hello"); return 0; &#125; 上面的程序在C中可以编译成功，但是在C++中就不行 在C++中，指针是不能指向一个常量的，但是在C中可以 12345678910111213141516#include &lt;stdio.h&gt; int main(void)&#123; int const j = 20; /* The below assignment is invalid in C++, results in error In C, the compiler may throw a warning, but casting is implicitly allowed */ int *ptr = &amp;j; // A normal pointer points to const printf("*ptr: %d\n", *ptr); return 0;&#125; 在C语言中，一个空指针可以直接指派给其他指针，如int，char 。但在C中，必须指定类型 1234567#include &lt;stdio.h&gt;int main()&#123; void *vptr; int *iptr = vptr; //In C++, it must be replaced with int *iptr=(int *)vptr; return 0;&#125; 下面的程序在C中可以编译，但是在C++中不行，必须为常量初始化 123456#include &lt;stdio.h&gt;int main()&#123; const int a; // LINE 4 return 0;&#125; Line 4 [Error] uninitialized const ‘a’ [-fpermissive] 在C中可以用C++的一些特定的关键字作为变量名 p.s. 这是自然，汗 123456#include &lt;stdio.h&gt;int main(void)&#123; int new = 5; // new is a keyword in C++, but not in C printf("%d", new);&#125; C++的检查会比C更严格，如： 1234567#include &lt;stdio.h&gt;int main()&#123; char *c = 333; printf("c = %u", c); return 0;&#125; error “invalid conversion from ‘int’ to ‘char*’”. 试了一些，确实是这样，感觉蛮有趣的！ 原文链接]]></content>
      <categories>
        <category>C/C++</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[我的第一篇博客]]></title>
    <url>%2F2015%2F03%2F15%2F%E6%88%91%E7%9A%84%E7%AC%AC%E4%B8%80%E7%AF%87%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[为了搞这个博客我确实花了不少功夫，从昨天晚上12点左右就开始了，看教程啊，然后自己操作去搞。加上一些教程由于时间的问题，总是存在着一些坑要填。不过麻烦归麻烦，我也总算是在3点的时候把东西推到github上面去了。 今天在申请免费的一级域名，免费的太难找到了，找到的又都是坑。反正这段时间域名解析什么的就慢慢来吧，不着急。 以前没有认真看markdown，只是能把每次的东西更新到tower上就满足了。现在还是认真看看markdown吧，毕竟写就要认真写。 p.s. 附上一个大坑，也提醒一下我自己一定记住冒号后面留一个空格]]></content>
      <categories>
        <category>杂项</category>
      </categories>
  </entry>
</search>
