<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[炼丹实战(3):手写数字识别]]></title>
    <url>%2F2019%2F03%2F07%2Ftensorflow-learning-3%2F</url>
    <content type="text"><![CDATA[前言既然已经踏上了漫漫的炼丹之路，那么接下来的修行就必不可少。上一篇用一些实例来演示了 TensorFlow 是如何工作的，但那只是简单的回归而已，不能算是真正的炼丹。这一篇，我们就聊一聊几乎每个人都会用来作为 TensorFlow 实践的第一个项目的——手写数字识别。 MNIST 数据集既然是训练一个能够识别手写数字的模型，那么手写数字的数据就必不可少。MNIST 数据集是一个几乎被每个炼丹师都用过的数据集了，每一个 TensorFlow 的教程一个都会对它下手。下面来介绍一下 MNIST 数据集。 MNIST 数据集在 http://yann.lecun.com/exdb/mnist/ 可以下载，来自美国国家标准与技术研究所, National Institute of Standards and Technology (NIST)。训练集包含了 250 个不同人的手写数字，其中 50% 是高中学生，50% 来自人口普查局的工作人员。测试集的数据是同样的比例。 数据分为4个文件，分别是「训练集图像」、「训练集标签」、「测试集图像」、「测试集标签」 train-images-idx3-ubyte.gz: training set images (9912422 bytes) train-labels-idx1-ubyte.gz: training set labels (28881 bytes) t10k-images-idx3-ubyte.gz: test set images (1648877 bytes) t10k-labels-idx1-ubyte.gz: test set labels (4542 bytes) 训练集（mnist.train）有 55000 行，验证集（mnist.validation）有 5000 行，测试集（mnist.test）有 10000 行。训练集的每一张图片（mnist.train.images）有 28 * 28 = 784 个像素点，即整个训练集可以转化为 [55000, 784] 的矩阵。 通过以下的简单操作就可以看到图片了： 12345img = np.array(mnist.train.images[1])img = img.reshape(28, 28)plt.figure()plt.imshow(img, cmap='gray')plt.show() 上图就是训练集的前两张图片。图片长什么样子其实根本不重要啦，毕竟训练的时候不过都是些矩阵而已，最终也可以根据标签来判断准确率，没必要把图片都展示出来。 坯子想得到一个能够识别手写数字的模型，我们先来一个没有中间层的吧！输入层 784 个节点之间连接到输出层的 10 个节点上（输出层的 10 个节点对应 10 个数字，选择数值最大的节点作为结果），这样的模型应该算得上是简单暴力了吧！当然，这样做的准确率一定是不高的，不过我们可以之后慢慢调整嘛。炼丹怎么会一次成功呢？ 12345678910111213141516171819202122232425262728293031import tensorflow as tfimport numpy as npfrom tensorflow.examples.tutorials.mnist import input_datamnist = input_data.read_data_sets("MNIST_data", one_hot=True)batch_size = 100n_batch = mnist.train.num_examplesx = tf.placeholder(tf.float32, [None, 784])y = tf.placeholder(tf.float32, [None, 10])W = tf.Variable(tf.zeros([784, 10]))b = tf.Variable(tf.zeros([10]))prediction = tf.nn.softmax(tf.matmul(x, W) + b)loss = tf.reduce_mean(tf.square(y - prediction))train_step = tf.train.GradientDescentOptimizer(0.2).minimize(loss)correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(prediction, 1))accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))with tf.Session() as sess: sess.run(tf.global_variables_initializer()) for epoch in range(21): for batch in range(n_batch): batch_xs, batch_ys = mnist.train.next_batch(batch_size) sess.run(train_step, feed_dict=&#123;x: batch_xs, y: batch_ys&#125;) test_acc = sess.run(accuracy, feed_dict=&#123;x: mnist.test.images, y: mnist.test.labels&#125;) train_acc = sess.run(accuracy, feed_dict=&#123;x: mnist.train.images, y: mnist.train.labels&#125;) print "Iter " + str(epoch) + " , Training Accuracy " + str(train_acc) + " , Testing Accuracy " + str(test_acc) 程序解释 MNIST 数据集可以由 tensorflow.examples 下载，其中 “MNIST_data” 是放数据的目录名（没有该目录会创建目录），one_hot 指标签采用 [0,0,1,0,…] 这样的形式，结果是几，第几位的数字就是 1 ，其他 9 位都是 0 。 batch_size 表示数据一批一批的传入，每一批 100 组数据 softmax 函数可以将输出映射为 0~1 的值，正好对应概率，同时，该函数会隐藏比较小的数而放大比较大的数。更多关于 softmax 函数的介绍可以参考维基百科 。 程序结果123456789101112131415161718192021Iter 0 , Training Accuracy 0.92636365 , Testing Accuracy 0.9262Iter 1 , Training Accuracy 0.9321455 , Testing Accuracy 0.9288Iter 2 , Training Accuracy 0.93523633 , Testing Accuracy 0.9299Iter 3 , Training Accuracy 0.93756366 , Testing Accuracy 0.9307Iter 4 , Training Accuracy 0.93874544 , Testing Accuracy 0.931Iter 5 , Training Accuracy 0.93994546 , Testing Accuracy 0.9313Iter 6 , Training Accuracy 0.9410909 , Testing Accuracy 0.9314Iter 7 , Training Accuracy 0.94207275 , Testing Accuracy 0.9311Iter 8 , Training Accuracy 0.9428727 , Testing Accuracy 0.9307Iter 9 , Training Accuracy 0.94354546 , Testing Accuracy 0.9308Iter 10 , Training Accuracy 0.9443273 , Testing Accuracy 0.9303Iter 11 , Training Accuracy 0.9447273 , Testing Accuracy 0.9296Iter 12 , Training Accuracy 0.9454 , Testing Accuracy 0.9298Iter 13 , Training Accuracy 0.9456364 , Testing Accuracy 0.9301Iter 14 , Training Accuracy 0.94603634 , Testing Accuracy 0.93Iter 15 , Training Accuracy 0.94632727 , Testing Accuracy 0.9295Iter 16 , Training Accuracy 0.94698185 , Testing Accuracy 0.9298Iter 17 , Training Accuracy 0.94734544 , Testing Accuracy 0.9311Iter 18 , Training Accuracy 0.9475273 , Testing Accuracy 0.9311Iter 19 , Training Accuracy 0.9479091 , Testing Accuracy 0.9315Iter 20 , Training Accuracy 0.9483455 , Testing Accuracy 0.9315 上面是程序运行的结果，可以看到 93.15% 的测试集都识别成功了。但是这显然是不够的，我们还可以优化程序，让模型的正确率更高。 那么下一步，让我们修改模型，让预测的准确率（测试集）提升到 95% 以上吧，漫漫炼丹路就要开始咯~~ 未完待续]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>Python</tag>
        <tag>TensorFlow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[炼丹实战(2):第一炉丹]]></title>
    <url>%2F2019%2F03%2F05%2Ftensorflow-learning-2%2F</url>
    <content type="text"><![CDATA[前言上一篇了解了丹炉后，那么这一次，我们就要动手实践，炼制自己的第一炉丹药了。万事皆应由易向难，说到最简单的丹药，那自然是一品丹药「回春散」了。咳咳~ 那么这一篇就从简单的回归讲起，主要是让大家熟悉一下，TensorFlow 的处世哲学，看看 TensorFlow 是怎么解决问题的。 粗糙的·回春散最简单的回归问题当属线性回归了，线性回归的问题估计每位同学都在初中就有所接触。我还记得，当时我们老师不允许我们用计算器，用「最小二乘法」算一次线性回归的问题，那起码是十来分钟啊。当然，这还不包括有时粗心算错数值，三次得出三个不一样的结果了。 「最小二乘法」用于解决线性拟合的问题，可以以最小的损失找到一条拟合散点的直线。而且也有现成的公式，一个循环，或者矩阵相乘就能解决。但是 TensorFlow 处理问题的逻辑不是这样的，那么就来看看 TensorFlow 是怎么解决问题的吧！ 我们使用更加简单的问题，就是没有误差的一条直线，让 TensorFlow 来解决。 12345678910111213141516171819import tensorflow as tfimport numpy as npx_data = np.random.rand(10)y_data = x_data * 0.1 + 0.2b = tf.Variable(0.)k = tf.Variable(0.)y = k * x_data + bloss = tf.reduce_mean(tf.square(y_data - y))train = tf.train.GradientDescentOptimizer(0.2).minimize(loss)with tf.Session() as sess: sess.run(tf.global_variables_initializer()) # Variable(变量)使用前需要初始化 for step in range(401): sess.run(train) if step % 20 == 0: print step, sess.run([k, b]) 这里的数据是随机生成的 10 组，但每一个点准确的落在 $ y = kx+b $ 这条直线上。 注意看 sess 这个员工每一次干了什么事：首先他要运行 train 这个 op，而 train 这个 op 的任务是「使用梯度下降法，让 loss 变得最小」，继续追溯， $ loss = \frac{\sum{(y_{data} - y)^2}}{n} $ ， $ y = k·x_{data} + b $ ，那么整个的任务中，就只有 k 和 b 是可以调整的变量。因此，sess 这个员工就会依照「梯度下降法」的原则，不断的调整 k 和 b。 TensorFlow 的这种处理问题的逻辑和平时的公式或者特定的算法不一样，简单的说，就是 不断的调整可变量，使得误差最小 。这种逻辑在处理线性回归这种简单的问题上时显得繁琐了一些，但是若是处理更加复杂的问题，就会简单得多。因为，复杂的问题，还是一样地缩小误差，不是吗？ 上面的代码让每训练20次输出一次结果，那么一起来看看结果吧： 1234567891011121314151617181920210 [0.037390854, 0.09433242]20 [0.09015258, 0.20382951]40 [0.094809845, 0.20201874]60 [0.09726442, 0.20106402]80 [0.09855816, 0.20056081]100 [0.09924004, 0.20029558]120 [0.09959945, 0.2001558]140 [0.09978888, 0.20008212]160 [0.09988872, 0.20004328]180 [0.09994134, 0.20002282]200 [0.099969074, 0.20001203]220 [0.09998371, 0.20000634]240 [0.099991426, 0.20000334]260 [0.09999547, 0.20000176]280 [0.09999761, 0.20000094]300 [0.09999873, 0.20000051]320 [0.09999934, 0.20000026]340 [0.09999966, 0.20000014]360 [0.09999981, 0.20000008]380 [0.09999985, 0.20000006]400 [0.09999985, 0.20000006] 可以看到，k 从一开始的 0.037 逐渐调整为 0.099，b 从一开始的 0.094 调整为 0.200。最忽略误差的情况下，我们可以认为程序已经找到了 k = 0.1, b = 0.2 的这个正确结果。 普通的·回春散那么这一次，我们来给数据掺杂，使得数据在 $ y = kx+b $ 的附近波动。 123456789101112131415161718192021222324252627import tensorflow as tfimport numpy as npimport matplotlib.pyplot as pltx_data = np.linspace(-0.5, 0.5, 20)noise = np.random.normal(0, 0.01, x_data.shape)y_data = 0.1 * x_data + 0.2 + noiseb = tf.Variable(0.)k = tf.Variable(0.)y = k * x_data + bloss = tf.reduce_mean(tf.square(y_data - y))train = tf.train.GradientDescentOptimizer(0.2).minimize(loss)with tf.Session() as sess: sess.run(tf.global_variables_initializer()) for step in range(401): sess.run(train) if step % 20 == 0: print step, sess.run([k, b]) prediction = sess.run(y)plt.figure()plt.scatter(x_data, y_data)plt.plot(x_data, prediction, 'r-', lw=5)plt.show() 还是一样的逻辑，下面是运行结果： 还有训练的数据： 1234567891011121314151617181920210 [0.0039783507, 0.07995532]20 [0.05889236, 0.19988391]40 [0.08481223, 0.19988827]60 [0.097046636, 0.19988827]80 [0.10282137, 0.19988827]100 [0.1055471, 0.19988827]120 [0.10683367, 0.19988827]140 [0.107440926, 0.19988827]160 [0.107727565, 0.19988827]180 [0.10786287, 0.19988827]200 [0.107926734, 0.19988827]220 [0.10795687, 0.19988827]240 [0.107971095, 0.19988827]260 [0.107977815, 0.19988827]280 [0.107981, 0.19988827]300 [0.107982494, 0.19988827]320 [0.10798319, 0.19988827]340 [0.10798353, 0.19988827]360 [0.10798368, 0.19988827]380 [0.10798372, 0.19988827]400 [0.10798372, 0.19988827] 可以看到，即使数据有所波动，程序还是准确的将 k 和 b 调整到了 0.1 和 0.2 的附近。 PS：要注意的是，TensorFlow 的数据的值也要在 Session 中使用 run() 来获取哦！ 优秀的·回春散线性回归的问题解决了，那么来试试非线性的吧！ 这里就直接用掺杂的数据了。 12345678910111213141516171819202122232425262728293031import tensorflow as tfimport numpy as npimport matplotlib.pyplot as pltx_data = np.linspace(-0.5, 0.5, 200)[:, np.newaxis]noise = np.random.normal(0, 0.02, x_data.shape)y_data = np.square(x_data) + noisex = tf.placeholder(tf.float32, [None, 1])y = tf.placeholder(tf.float32, [None, 1])a = tf.Variable(0.)b = tf.Variable(0.)c = tf.Variable(0.)y_pre = a * tf.square(x) + b * x + closs = tf.reduce_mean(tf.square(y - y_pre))train_step = tf.train.GradientDescentOptimizer(0.1).minimize(loss)with tf.Session() as sess: sess.run(tf.global_variables_initializer()) for i in range(2000): sess.run(train_step, feed_dict=&#123;x: x_data, y: y_data&#125;) prediction_value = sess.run(y_pre, feed_dict=&#123;x: x_data&#125;) print 'result: ', sess.run([a, b, c])plt.figure()plt.scatter(x_data, y_data)plt.plot(x_data, prediction_value, 'r-', lw=5)plt.show() 这里的 x 和 y 的数据都是在使用的时候传进去的，而不是像前面一样一开始就定死的。placeholder 和 feed 具体的用法可以自行搜索， 下面是拟合的结果： 输出的参数 a, b, c： 1result: [0.9012379, -0.008498974, 0.008641074] 精良的·回春散对深度学习和神经网络有一些了解的小伙伴应该可以看出来，上面的三个都是只有输入和输出层，没有中间层的。而且，上面的程序都是我们确定好了回归的类型，即我们知道结果应该是线性，或者二次函数，然后我们去拟合它，寻找最佳的参数。既然要用 TensorFlow，那么自然也要加一层中间层才像样子嘛~ 前面的模型都是： 【输入层】 =====( * 权重 + 偏置值) =====&gt; 【输出层】 加了中间层之后： 【输入层】 =====( * 权重 + 偏置值) =====&gt; 【中间层】 =====( * 权重 + 偏置值) =====&gt; 【输出层】 中间层的节点可以不止一个，因此，两级的权重和偏置值都是矩阵的形式。不同于前面的，我们不需要知道我们拟合的是什么类型的函数，我们只需要中间的两层权重和偏置值矩阵就行了；我们也不需要知道这两层的值是怎么调整出来的，因为 TensorFlow 会自动为我们调整；我们更不需要知道为什么这样可以，只要准确率达到我们的期望就可以。我们需要做的，只是将图的结构画出来，Session 会直接根据变量之间的关系进行调整。 如上图所示，输入的 x 与 1 行 10 列的权重矩阵相乘，得出一个 1 行 10 列的矩阵，再加上同样是 1 行 10 列的偏置值，成为中间节点的值。中间节点值为 1 行 10 列的矩阵，与第二层 10 行 1 列的权重矩阵做矩阵乘法，得出一个 1 行 1 列的数值，加上第二层的偏置值，结果就是输出 y。我们说需要的就是两层的权重和偏置值，但是为什么这样，原理是什么，为什么它这样可以拟合，我们完全不需要知道。 注意： 上图没有画激励函数的部分，乘上权重加上偏置值之后需要放入激励函数中，以引入非线性因素（如果不加入的话，y 和 x 依然是「线性关系」），更多关于激励函数的内容可以自行上网搜索。 接下来就是代码的部分了： 12345678910111213141516171819202122232425262728293031323334import tensorflow as tfimport numpy as npimport matplotlib.pyplot as pltx_data = np.linspace(-0.5, 0.5, 200)[:, np.newaxis]noise = np.random.normal(0, 0.02, x_data.shape)y_data = np.square(x_data) + noisex = tf.placeholder(tf.float32, [None, 1])y = tf.placeholder(tf.float32, [None, 1])Weight_L1 = tf.Variable(tf.random_normal([1, 10]))biases_L1 = tf.Variable(tf.zeros([1, 10]))Wx_plus_b_L1 = tf.matmul(x, Weight_L1) + biases_L1L1 = tf.nn.tanh(Wx_plus_b_L1)Weight_L2 = tf.Variable(tf.random_normal([10, 1]))biases_L2 = tf.Variable(tf.zeros([1, 1]))Wx_plus_b_L2 = tf.matmul(L1, Weight_L2) + biases_L2prediction = tf.nn.tanh(Wx_plus_b_L2)loss = tf.reduce_mean(tf.square(y - prediction))train_step = tf.train.GradientDescentOptimizer(0.1).minimize(loss)with tf.Session() as sess: sess.run(tf.global_variables_initializer()) for i in range(2000): sess.run(train_step, feed_dict=&#123;x: x_data, y: y_data&#125;) prediction_value = sess.run(prediction, feed_dict=&#123;x: x_data&#125;)plt.figure()plt.scatter(x_data, y_data)plt.plot(x_data, prediction_value, 'r-', lw=5)plt.show() 使用 tanh 作为激励函数 使用梯度下降法训练 损失为差平方的均值 注意观察两层的网络结构以及数据之间的流动关系 运行的结果： 注意观察曲线的两端，可以明显的看到和之前二次函数直接拟合的区别。 后记上文 4 段代码解决了一些简单的回归问题，通过这些问题的解决，我们可以看出 TensorFlow 简单但又十分高效的处理问题的逻辑。在今后的漫漫炼丹路上，可能会遇到更多复杂的问题，但自动化的炼丹让我们可以将更多的精力投入到丹方的研究上。 要学习的内容还有很多，加油吧~~]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>Python</tag>
        <tag>TensorFlow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[炼丹实战(1):丹炉的使用]]></title>
    <url>%2F2019%2F03%2F04%2Ftensorflow-learning-1%2F</url>
    <content type="text"><![CDATA[前言最近嘛，准备开始炼丹，虽然我的博客没什么人看，但是我还是打算把一些过程记录下来，假使以后不炼丹，忘了，也能很快回忆起来。所以，新坑就这么开起来吧~~~ 另外，机器学习的学习笔记，emmm，不打算继续写了（也许以后有时间会简要地写一下后面的内容吧，也说不定） 所谓「炼丹」嘛，就是训练 AI 模型。每次训练都要调整几个参数，然后等上短则半个小时，长则几天几夜，然后训练出一个准确率并不一定能达到期望的模型。就像炼丹一样，不断调整药材的配比，放丹炉里炼上个七七四十九天，结果出来一炉废丹一样。简直一模一样嘛！我有感觉：我如果有朝一日成为一名合格的炼丹师，那么我的耐心一定会锻炼的很好 QAQ “工欲善其事必先利其器”，要成为一名合格的炼丹师，除非你是天赋异禀的炼丹奇才，能丹火化鼎，在空中结丹，不然还是要选择一个好的丹炉要紧。所谓好的丹炉嘛，当然要质量上乘，生产厂家得是知名大厂；其次，最好能足够聪明，我把丹方输进去，它能自动炼丹，就像《校花的贴身高手》里面的那个高科技自动炼丹炉一样（话说这个小说为什么现在都还在更新啊~）。因此，我推荐知名大厂——谷歌——出品的丹炉：TensorFlow。质量过硬，炼丹过程足够智能，是居家旅行的必备之选。 那么接下来就来认识一下 TensorFlow 吧！ 安装TensorFlow 是一个 Python 的包，因此直接用 pip 安装就行了。当然个人推荐用 anaconda 创建虚拟环境安装。 TensorFlow 有 CPU 和 GPU 两个版本，可以按照需要选择安装，当然，GPU 的运算能力确实强悍，2080Ti 买起来啊！毕竟强大的光追，炼丹之余，还可以玩玩《地铁》对吧。 12pip install tensorflow # cpu versionpip install tensorflow-gpu # gpu version 另外，似乎忘了说 TensorFlow 的官网了，国内也可以直接连得上呢。 语法TensorFlow 是 Python 的一个库，自然语法和 Python 是一样的，然而 TensorFlow 有着比较与众不同的逻辑，接下来，我们就看看 TensorFlow 程序由哪些部分构成的吧！ Tensor : 张量，可以简理解为数据，TensorFlow 就是数据流动 Graphs : 图，TensorFlow 使用图来表示计算任务，就像 boss 交给你的一份任务清单，上面写满了你要做的事 Session : 会话，图需要在会话里启动，就像公司的员工，拿到任务清单就要开始干活 Operation : 操作，图中的节点，执行计算，接收并产生 Tensor，也就是任务清单上的每一项单独的任务 还有一些如变量、常量的东西，feed、fetch 之类的操作，我认为不算是 TensorFlow 程序的组成结构，在此就不说了，后面遇到可以搜一下，结合代码理解。 第一个程序不管是学什么，对于一个程序员来说，”Hello World” 这么神圣的东西，是一定要写一遍的。那么就直接上代码吧，可以成功输出的，就算是安装好了。 12345import tensorflow as tfhello = tf.constant("Hello, World!")sess = tf.Session()print sess.run(hello)sess.close() 稍微解释一下吧： TensorFlow 使用constant()方法创建常量 使用 Session() 方法创建会话，同时会创建一个默认图，之前说过的，Session 像一个员工，进入公司时自带了一份任务清单，使用 run() 方法让他来执行任务（Session 会按图索骥，执行完当前任务所需要的全部前置任务，当然了，本例的 Session 只有一个任务：创建一个常量了）]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>Python</tag>
        <tag>TensorFlow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[痒痒鼠自动刷妖气封印]]></title>
    <url>%2F2019%2F02%2F18%2Fonmyoji-support%2F</url>
    <content type="text"><![CDATA[之前在玩痒痒鼠的时候，苦于刷副本比较累，于是写了自动刷妖气封印的代码。现在对痒痒鼠兴致缺缺，在整理电脑文件的时候就把代码整理上传到了 GitHub 上了。这里记录一下整个代码的结构和思路备忘。 目录结构整个程序包含3个 Python 文件和两个目录，如下： pic : 用于放置一些用来确定场景进行比较的图片 usr : 用于放置用户名的截图 baseFunction.py : 定义了一些鼠标的基本操作 order.py : 定义了按钮位置、尺寸大小等信息；每个副本的操作流程在此 yysgo.py : 程序入口 使用 在 usr 目录下添加一张游戏名称的截图（部分截图即可，需要 png 格式）。如下图 zhzz.png（我的游戏名称是“最后之作”） ： 在命令行输入 python yysgo.py user_name what_to_do times code user_name : 你放在 usr 目录下的截图文件名，不包含格式后缀，如上面的应该是 zhzz What_to_do : 需要刷的副本，使用拼音首字母。如鬼使黑的话就是 gsh times : 需要刷的次数 code : 0~7 的数字，内容如下： &nbsp; &nbsp; 接受房主 不当房主&nbsp;&nbsp; 有活动 无活动 有活动 无活动 &nbsp;接受邀请 &nbsp;7 6&nbsp; 5&nbsp; 4&nbsp; &nbsp;不接受邀请 &nbsp;3 2&nbsp; 1&nbsp; 0&nbsp; ​ （其中的活动指的是痒痒鼠经常会有的一些鬼王活动，使得原本的「妖气封印」按钮下移一格） eg. python yysgo.py zhzz gsh 100 6 表示刷100次鬼使黑，接受悬赏封印邀请，若原房主退出则接受房主，没有特殊活动 程序内容整个程序的原理比较简单，就是模拟平时手动刷副本时的操作而已。 baseFunction.pybaseFunction.py 内定义了一些基本的鼠标操作，如： 点击 ：click(area, delay=0.5) area ：点击区域 delay ：延时最大值（后面的 delay 皆是如此） 拖拽 ：drag(begin_area, end_area, delay=0.5, duraction=0.5) begin_area ：开始区域 end_eare ：结束区域 duraction ：拖拽最大时长 寻找图片 ：find_picture(file_location)，返回 T/F file_location ：图片文件文字 以及基于这些操作的一些其他操作，如： 滚动 ：roll(block_nums, area, block_height, eps=2, delay=0.5, duraction=0.5) block_nums ：滚动格数，负数为从长往下拖拽一格，正数为从下往上 area ：可以操作的列表区域 block_height ：一格的高度 eps ：误差 检测邀请 ：check_invatation(operation, pic, button_accept, button_decline) operation ：收到悬赏封印邀请的操作 pic ：悬赏封印邀请的截图位置 button_accept ：「接受」按钮区域 button_decline ：「拒接」按钮区域 检测房主 ：check_roomowner(pic)，返回 T/F pic ：成为房主时的标志图片（默认使用亮起的「开始战斗」按钮的截图作为已经成为房主的依据） 检测等待状态 ：check_searching(pic, button)，无返回值，若不在匹配中，则点击「开始匹配」继续 pic ：正在匹配的标志图片（默认使用亮起的「取消匹配」按钮的截图作为正在匹配中的依据） 等待 ：waiting(symbol, invatation_pic, invatation_operation, roomowner_pic, searching_pic, button_set) symbol ：进入战斗（「准备」按钮亮起）的标志图片 *_pic ：上面三个检测的图片位置 invatation_operation ：收到悬赏封印邀请的操作 button_set ：按钮的位置的 list，[button_accept, button_decline, button_search] 注意 ： 图片的检测使用最原始的逐像素比对，因此若图片大小不对也会导致无法检测，这一点有兴趣的同志可以改进一下。在自行截图时要注意游戏的某些位置是动态的，或者的动态的底层上加一层半透明图片，这会导致图片检测失效。 这里与时间相关的参数都是时间的最大值，程序执行时等待的对应时间都是从0到该「最大值」的随机数，以避免防作弊检测 同理，这里所有的按钮的点击还有拖拽的操作，位置都是随机的。每一个 area（或 button） 都是 [[x1, y1], [x2, y2]] 的形式 order.pyorder.py 定义了一些组合操作（即刷一个副本的完整操作，使用 baseFunction 的函数，也可以自行在此添加其他副本的操作），设置了一些有关按钮和相关检测区域位置坐标的参数。 副本操作示例（部分内容省略）12345678910111213141516171819202122232425262728293031323334353637def guishihei(count, invitation_op, roomowner_op, user_name, activities=False): # count : 刷该副本的次数 # *_op, activities : 对应上面表格 # user_name : 用户名(与上文一致，即截图的文件名) while(count - index &gt; 0): pyautogui.moveTo(1, 1, 0.3) # 为防止鼠标的遮挡，每次需要匹配图片之前，将鼠标移动到左上角，后面不再出现这行代码 #### 执行副本组队的一连串操作 baseFunction.waiting(get_start_symbol(user_name), PIC_INVATATION, invitation_op, PIC_ROOMOWNER, PIC_IS_SEARCHING, button_set) # 若检测到 user_name.png 在屏幕中，则认为可以开始新一轮操作，否则继续等待 baseFunction.click(get_button(TEAM)) # 点击『组队』按钮 if activities: baseFunction.roll(1, get_button(AREA[0]), block_height) baseFunction.click(get_button(DEMON_SEAL)) # 点击『妖气封印』按钮，若有特殊活动，将列表下滚一格再点击 drag_area = [get_button(AREA[1][0]), get_button(AREA[1][1])] # 计算拖动区域 baseFunction.roll(8, drag_area, block_height_l2) # 下滚列表 baseFunction.click(get_button(GUI_SHI_HEI)) # 点击『鬼使黑』按钮 baseFunction.click(get_button(MATCH)) # 点击『自动匹配』 interupt = baseFunction.waiting(PIC_READY, PIC_INVATATION, invitation_op, PIC_ROOMOWNER, PIC_IS_SEARCHING, button_set) # 检测『准备』按钮是否出现 #### 特殊情况的处理 if interupt == 1: # 1 表示成为房主了(waiting()函数会每隔一段时间检测悬赏封印邀请和房间状态，正常状态返回 0) if roomowner_op: baseFunction.click(get_button(START)) # 若接受成为房主，则点击『开始战斗』按钮开始 if baseFunction.waiting(PIC_ROOMOWNER, PIC_INVATATION, invitation_op, PIC_ROOMOWNER, PIC_IS_SEARCHING, button_set) == 0: # 由于检测房主间隔时间较长，有可能执行到这里时其他玩家退出了，因此需要等待『开始战斗』按钮重新亮起 baseFunction.click(get_button(START)) baseFunction.waiting(PIC_READY, PIC_INVATATION, invitation_op, PIC_ROOMOWNER, PIC_IS_SEARCHING, button_set) # 等待『准备』按钮 else: baseFunction.click(get_button(BACK)) # 若不接受房主，左上角返回，开始下一轮 countinue #### 到这里准备按钮亮起，玩家已经进入副本并可以开始战斗了 baseFunction.click(get_button(PREPARE)) # 点击『准备』按钮 #### 战斗完成，点击任意位置退出 baseFunction.waiting(PIC_FINISH, PIC_INVATATION, invitation_op, PIC_ROOMOWNER, PIC_IS_SEARCHING, button_set) baseFunction.click(get_button(FINISH)) 部分参数设置(分辨率等参数不同，最好使用前重新测定坐标） block_height_l1/l2 : 列表一格的高度，我在测量时 妖气封印的子列表(l2) 和其本身的列表(l1) 高度并不一样 BASE : 基准点，后面的所有坐标都是对此坐标的相对位置，采取窗口左上角坐标作为基准点 ACCEPT, DECLINE, BACK, START : （悬赏封印）接受/拒绝，返回，开始战斗 按钮的位置 MATCH, PREPARE, FINISH : 自动匹配，准备，完成（点击任意位置退出） 按钮的位置 TEAM, DEMON_SEAL : 组队（庭院界面），妖气封印 按钮的位置 AREA : 列表的区域，roll() 函数需要这个区域来确定拖动的界限，AREA[0]是点击组队后出现的列表(l1)，AREA[1]是妖气封印下的子列表(l2) PIC_*, USER_BASE : 各种图片位置，用户名截图目录 yysgo.py程序入口，不用多说。 在 order.py 中添加新的操作后，需要在这里调用。 备注 图片检测的速度不够快，这有时会导致一些意料之外的事发生 逐一像素检测图片会导致以后若有改版，需要重新截图 order.py 中对特殊状况的处理似乎有一些错误，不过在实际使用中没有发生意外，就没有修改了st=>start: 开始 cond1=>condition: 处于主界面？ cond2=>condition: 「准备」按钮亮起？ cond3=>condition: 检测战斗是否完成 cond4=>condition: 是否达到设定次数 op1=>operation: 「组队」->「妖气封印」->「对应副本」->「自动匹配」 op5=>operation: 「准备」 op6=>operation: 空白处任意点击 e=>end: 结束 st->cond1 cond1(yes)->op1 cond1(no)->cond1 op1->cond2 cond2(yes)->op5 cond2(no)->cond2 op5->cond3 cond3(yes)->op6 cond3(no)->cond3 op6(right)->cond4 cond4(yes)->e cond4(no)->cond1{"scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12} var code = document.getElementById("flowchart-0-code").value; var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-0-options").value)); var diagram = flowchart.parse(code); diagram.drawSVG("flowchart-0", options);]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用 dlib 对人脸特征点标记]]></title>
    <url>%2F2018%2F02%2F24%2Fface-landmark-with-dlib68%2F</url>
    <content type="text"><![CDATA[我在做表情识别的时候，使用的是 CK/CK+ 的数据集，然而令人难受的是，我一直不知道如何去标记人脸特征点。因为数据集里面有标记好的 Landmarks，都放在里面了。所以我训练是直接用这个数据的，测试集其实也是从里面随机抽取的。 然而昨天在找资料的时候，我很敏感的发现了68这个数字。天哪，我怎么会忘记，这个就是 CK/CK+ 数据集里面标记点的个数啊！ 于是，我开始了 dlib 的调试。 配置话不多说，还是： macOS + anaconda + Python2.7 dlib 的安装：对于 Mac 用户，参见这一篇 其实我根本就是忘记了我在安装 face_recognition 时曾经在 Python3 的环境下安装过 dlib 了。看这里 特征检测器需要下载特征检测器，当然你也可以自己训练 (/滑稽) 下载后可以解压出一个 dat 文件，我们需要的就是这个。 检测人脸之前就说过，dlib 也是可以检测人脸的。 12detector = dlib.get_frontal_face_detector()faces = detector(img, 1) 这样，faces 里面就存储了所有脸部区域的范围。 值得注意的是，faces[i] 是第 i 张脸，使用.top() .bottom() .left() .right()四个函数得到具体的值 特征点标记加载刚刚下载的文件来标记特征点。 12landmark_predictor = dlib.shape_predictor('./shape_predictor_68_face_landmarks.dat')shape = landmark_predictor(img,face_area) 其中，shape 就保存了特征点的信息。 为了得到特征点的坐标，需要使用.part()函数，如下: 12x[i] = shape.part(i).xy[i] = shape.part(i).y 特征点是有顺序的，如下图： 68个特征点的位置如下： 12345678910&#123; IdxRange jaw; // [0 , 16] IdxRange rightBrow; // [17, 21] IdxRange leftBrow; // [22, 26] IdxRange nose; // [27, 35] IdxRange rightEye; // [36, 41] IdxRange leftEye; // [42, 47] IdxRange mouth; // [48, 59] IdxRange mouth2; // [60, 67]&#125; 实战1234567891011121314151617181920# -*- coding:utf-8 -*-import cv2import dlibdetector = dlib.get_frontal_face_detector()landmark_predictor = dlib.shape_predictor('./shape_predictor_68_face_landmarks.dat')img = cv2.imread('./lyf2.png')faces = detector(img, 1)if (len(faces) &gt; 0): for k,d in enumerate(faces): # cv2.rectangle(img,(d.left(),d.top()),(d.right(),d.bottom()),(255,255,255)) shape = landmark_predictor(img,d) for i in range(68): img2 = cv2.circle(img, (shape.part(i).x, shape.part(i).y),5,(0,255,0), -1, 8) img2 = cv2.putText(img,str(i),(shape.part(i).x,shape.part(i).y),cv2.FONT_HERSHEY_SIMPLEX,0.5,(255,2555,255))cv2.imshow('Frame',img)cv2.imwrite('./landmark.jpg', img2)cv2.waitKey(0) 效果如下： 蛤，你问 Landmark 还可以用来干嘛？ 当然是让美帝也感受一下膜法的力量！！！ 根据眼睛眉毛附近的点，来设计黑框眼镜的位置和大小。 代码很简单，我就不放了]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>Python</tag>
        <tag>人脸识别</tag>
        <tag>情感识别</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用 OpenCV 检测人脸]]></title>
    <url>%2F2018%2F02%2F24%2FFace-recog-with-opencv%2F</url>
    <content type="text"><![CDATA[在做表情识别的时候，突然在《机器学习——算法原理与编程实践》一书中看到了人脸检测的部分。书中使用的是 OpenCV 自带的 Haar 特征级联表作为训练集，标记人脸的。这种方法我之前也在网上看到过，因为没有成功（现在看来应该是使用了错误的表造成的）所以使用了 face_recognition 的库来进行的。 现在既然成功完成了这种方法，那自然也要用起来。 前期配置这一次的表情识别的前期工作都是用 Python2.7 做的，因此代码也是基于 Python2.7 的。Python3 的话，应该也是大同小异的。 建议使用 anaconda 配置 Python 虚拟环境，使用起来也很方便。 需要使用的特征级联表，书上使用 haarcascade_frontalface_alt_tree.xml 和 lbpcascade_frontalface.xml，我将使用后者。 上述两个文件分别在链接位置 haarcascades 和 lbpcascades 目录下。 使用方法关键代码123456789face_cascade = cv2.CascadeClassifier('./lbpcascade_frontalface.xml')# 参数说明：# gray：传入的图片，一般使用灰度图# 1.2： scaleFactor--表示在前后两次相继的扫描中，搜索窗口的比例系数。默认为1.1：即每次搜索窗口依次扩大10%# 3： minNeighbors--表示构成检测目标的相邻矩形的最小个数(默认为3个)。# 如果组成检测目标的小矩形的个数和小于 min_neighbors - 1 都会被排除。# 如果min_neighbors 为 0, 则函数不做任何操作就返回所有的被检候选矩形框，# 这种设定值一般用在用户自定义对检测结果的组合程序上faces = face_cascade.detectMultiScale(gray, 1.2, 3) 完整代码12345678910111213141516171819202122# -*- coding: utf-8 -*-from numpy import *import cv2face_cascade = cv2.CascadeClassifier('./lbpcascade_frontalface.xml')img = cv2.imread('./test.jpg')gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)faces = face_cascade.detectMultiScale(gray, 1.2, 3)for (x, y, w, h) in faces: img2 = cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 1) cv2.imwrite('./sample.jpg',img2) # 下面是面部区域的灰度图和原图，可以使用 imwrite 保存为文件 roi_gray = gray[y: y + h, x: x + w] roi_color = img[y: y + h, x: x + w]cv2.imshow('img', img)cv2.waitKey(0)cv2.destroyAllWindows() 效果图 P.S. 在使用 dlib 做面部特征点标记的时候，发现 dlib 也有 face_detector，有时间我会在下一篇文章中介绍一下。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>Python</tag>
        <tag>人脸识别</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Face Recognition的配置和初步使用]]></title>
    <url>%2F2018%2F01%2F19%2FFace-Recognition%2F</url>
    <content type="text"><![CDATA[由于新一届的物联网大赛有关于人脸识别的部分，因此老师让我给学弟学妹讲一讲有关人脸识别的部分。因为上次刷知乎的时候看到了一个圣诞节时的微信头像自动带圣诞帽的小程序用到了这个 face_recognition 的 Python 库，上网查了一下，发现离线识别率高达99.38%，因此就打算使用这个库了。 理想很丰满，现实很骨感。折腾了很长时间，不由得感叹，这个库是真 TMD 难配。 以下就是记录的一些过程吧！ 配置和安装需要的诸如 numpy、opencv 等的机器学习的常用库就不写了，这些不难，而且我早已配过了。重点是安装 dlib. 本次的配置基本参考face_recognition的 readme 需求： Python 3.3+ or Python 2.7 macOS or Linux (Windows not officially supported, but might work) 这里我使用的环境就是 Python3.6 + macOS，（作者已经说了，Windows 环境下没有测试，而且我看了网上好像 Windows 确实各种坑，所以小伙伴们还是不要去跳坑了吧，老老实实 Linux 吧） 安装 dlib作者有给连接指导怎样安装 dlib 的，How to install dlib from source on macOS or Ubuntu，但是这个网址被墙了，可以科学上网的同学就直接去看。 为了帮助无法科学上网的同学，我把 dlib 安装指导 copy 了过来： 前置工作： For macOS 安装 XCode （主要是 XCode command line utils） 安装 homebrew brew install boost-python --with-python3 --without-python For Linux sudo apt-get install libboost-all-dev 安装： clone the code from githubgit clone https://github.com/davisking/dlib.git build the main dlib librarycd dlibmkdir build; cd build; cmake .. -DDLIB_USE_CUDA=0 -DUSE_AVZ_INSTRUCTIONS=1; cmake --build build and install the python extensionscd ..python3 setup.py install --yes USE_AVX_INSTRUCTIONS --no DLIB_USE_CUDA 安装 face_recognition这个就没什么好说的了，pip3 install face_recognition 测试如果你进入 Python3，可以成功 import dlib ，就表示你的 dlib 成功安装了如果你在 terminal 内输入 face_ ，按 tab 键，能够自动补全 face_recognition 说明 face_recognition 已经成功安装了 备注作者提供了一个 virtualBox 的 Ubuntu 镜像，内部已经配置好了一切的环境，如果有需要可以点这里下载 直接使用前面在 terminal 里面，face_recognition 就已经可以直接使用了，具体的做法是： 1face_recognition 已知人物照片的目录 需要识别的照片目录 还可以加入一些参数，比如容忍度 --tolerance ，越小的容忍度，则识别时就越严格 加入 --show-distance true 可以显示两个人脸的差距，用于调整容忍度 代码前面的是直接使用 face_recognition 这个命令的，当然也可以在 Python 里面 import 这个库，做其他的处理 我在使用库的时候遇到了 No module named &#39;face_recognition&#39; 的问题，如果你也遇到了这个问题，并且你确定你在输入 pip3 list 后，face_recognition 这个库确实已经安装完成了。那么你可以在代码中加入下面两句以引用 face_recognition 12import syssys.path.append("/usr/local/lib/python3.6/site-packages/") 在添加了正确的路径之后，就可以正确的 import 这个包了（每个人的 site-packages 的位置不一定一样） 面部定位123image = face_recognition.load_image_file("./pic/obm2.jpg")face_locations = face_recognition.face_locations(image)print(face_locations) 首先使用 load_image_file 函数将需要识别的图片添加进去，再调用 face_locations 函数就可以返回面部的坐标，如下： 1[(1268, 2884, 1423, 2729), (1062, 2248, 1216, 2093), (1142, 2575, 1271, 2446), (1200, 1543, 1329, 1414), (1295, 3111, 1481, 2925), (1062, 2764, 1216, 2609), (1027, 3482, 1212, 3296), (1013, 1199, 1142, 1070), (1148, 1336, 1302, 1182), (1182, 1044, 1337, 889), (956, 1629, 1085, 1500), (1212, 778, 1398, 593), (1062, 1869, 1216, 1715), (956, 2532, 1085, 2403), (1406, 3510, 1628, 3287)] 其中，每一个脸部位置坐标是由4个数字的元组组成的，其分别为 $ x_1 , y_1 , x_2 , y_2 $ ，这两个点分别是确定脸部位置的两角，可以用 OpenCV 加载图片，并且使用切片操作截取脸部 123456index = 0for (x1, y1, x2, y2) in face_locations : print(x1, x2, y1, y2) f = img[x1 : x2, y2 : y1] index = index + 1 cv2.imwrite("hezhao_" + str(index) + ".jpg", f) 面部比较 加载已知的头像 123dt_image = face_recognition.load_image_file("./head/dt_1.jpg")sll_image = face_recognition.load_image_file("./head/sll_1.jpg")obm_image = face_recognition.load_image_file("./head/obm_1.jpg") 加载待识别的头像 1unknown_image_1 = face_recognition.load_image_file("./unknow_head/unknow_1.jpg") 编码 12345dt_encoding = face_recognition.face_encodings(dt_image)[0]sll_encoding = face_recognition.face_encodings(sll_image)[0]obm_encoding = face_recognition.face_encodings(obm_image)[0]unknown_encoding = face_recognition.face_encodings(unknown_image_1)[0] 输入结果 1results = face_recognition.compare_faces([dt_encoding, sll_encoding, obm_encoding], unknown_encoding[i]) 输出的结果是一个3个的 list，内部的值分别是 true 或者 false 表示是不是对应的人]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>Python</tag>
        <tag>人脸识别</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2017%2F02%2F11%2Fhello-world%2F</url>
    <content type="text"><![CDATA[写在前面由于重装系统的缘故，Github也是很久都没有使用过了（并不是因为我懒得写代码 /手动滑稽）。 由于今天突然想使用Github和用Hexo写博客了，因此花了些时间把东西弄起来了（很坑的东西是我以前配置Hexo时参考的博客居然404了，因此又重新找了好久，我在考虑着是不是应该自己写一个教程，方便以后参考） 我之前是有个spectop1017的Github账号的，这是因为我当时学习使用Github时不太会，也不知道怎么的申请了两个账号，也不知道怎么的使用了spectop1017这个账号去提交代码了。那个账号里面也没有什么东西了，基本上都是当时学习Android时一些练手的程序，在spectop1017.github.io上面写的一些博客我也搬到spectop.github.io这里了，那个账号就不打算再使用了。另外我在一大堆文件中居然找到了当时因为重装系统而丢失的第一批Blog的Markdown文件，真是意外之喜，就一起搬运过来了。 分割线：以下是Hexo自带的Hello world文档 Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
      <categories>
        <category>杂项</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[markdown文档中mathjax的问题]]></title>
    <url>%2F2016%2F01%2F29%2Fmarkdown%E6%96%87%E6%A1%A3%E4%B8%ADmathjax%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[在写markdown文档时经常会需要插入数学公式，我之前只会使用图片插入，上次在看到mathjax后，我开始了使用mathjax的历程，但在实际写文档的过程中遇到了一些问题。 关于有一些公式无法正确的显示在写机器学习的文章中遇到的一个关于范数的公式写出来编辑器上显示没有问题，但是一旦放进文档里就不行了，这个问题困扰了我很长时间。 这是代码：12&gt; 严格意义上讲，Minkowski Distance 不是一种距离，而是一组距离的定义&gt; $$ \lim_&#123;k\to\infty&#125;\left( \sum_&#123;i=1&#125;^n\mid p_i-q_i\mid ^k\right)^\frac&#123;1&#125;&#123;k&#125; $$ 这是效果： 严格意义上讲，Minkowski Distance 不是一种距离，而是一组距离的定义$$ \lim{k\to\infty}\left( \sum{i=1}^n\mid p_i-q_i\mid ^k\right)^\frac{1}{k} $$ 这里haroopad显示的公式是正确的，但是hexo编译过后的网页显示就不对了。 把代码剪裁一下，看看什么样子的公式是可以的：12&gt; 严格意义上讲，Minkowski Distance 不是一种距离，而是一组距离的定义&gt; $$ \lim_&#123;k\to\infty&#125;\left( \sum_i \right) $$ 效果： 严格意义上讲，Minkowski Distance 不是一种距离，而是一组距离的定义$$ \lim_{k\to\infty}\left( \sum_i \right) $$ 这个好像就可以，但是貌似sum后面的i一旦加上花括号就不行：12&gt; 严格意义上讲，Minkowski Distance 不是一种距离，而是一组距离的定义&gt; $$ \lim_&#123;k\to\infty&#125;\left( \sum_&#123;i&#125; \right) $$ 效果： 严格意义上讲，Minkowski Distance 不是一种距离，而是一组距离的定义$$ \lim{k\to\infty}\left( \sum{i} \right) $$ 于是我点开了两个网页的源代码，定位到这一行：1&lt;p&gt;严格意义上讲，Minkowski Distance 不是一种距离，而是一组距离的定义&lt;br&gt;$$ \lim&lt;em&gt;&#123;k\to\infty&#125;\left( \sum&lt;/em&gt;&#123;i&#125; \right) $$&lt;/p&gt; 1&lt;p&gt;严格意义上讲，Minkowski Distance 不是一种距离，而是一组距离的定义&lt;br&gt;$$ \lim_&#123;k\to\infty&#125;\left( \sum_i \right) $$&lt;/p&gt; 可以发现最明显的不同就算lim后面的 &lt;em&gt;，这时我们注意到，hexo在编译的时候将lim和sum后面的下划线 _翻译成强调的 &lt;em&gt; 了，仔细观察前面的公式，确实可以发现一部分变成了斜体。所以我们要在所有的下划线 _ 前面加上 \ 转义就可以了。 OK，搞定 p.s 我的chrome上显示的公式后面都有一个竖线，firefox没有，内啥，一般平时用chrome习惯，所以有人知道怎么弄咩？ 上面的问题在重新配置Hexo之后就没有了，个人觉得应该是版本的问题？]]></content>
      <categories>
        <category>Markdown</category>
      </categories>
      <tags>
        <tag>Markdown</tag>
        <tag>MathJax</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[「学习笔记」机器学习(1)]]></title>
    <url>%2F2016%2F01%2F22%2F%E3%80%8C%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E3%80%8D%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-1%2F</url>
    <content type="text"><![CDATA[科学算法库的安装(linux) 1.安装Numpysudo apt-get install python-numpy 2.安装Scipysudo apt-get install python-numpy 3.Matplotlibsudo apt-get install tk-dev sudo apt-get install python-gtk2-dev sudo apt-get install python-pyside 4.spyder GUI环境sudo apt-get install spyder 上述安装完毕后，可以利用 1234567891011#! /usr/bin/pythonimport numpy as npimport matplotlib.pyplot as pltx = np.linspace(0,4*3.1415,100)y = np.sin(x)plt.figure(figsize=(8,4))plt.plot(x,y,label="$sin(x)$",color="red",linewidth=2)plt.legend()plt.show() 进行测试。若生成正弦曲线窗口，则配置完成. NumPy的基本操作 Numpy 的导入import numpy as np 这种写法在使用相关函数的时候需要写明是哪个包的，如: myZero = np.zeros([3,5]) 还可以导入包全局使用 from numpy import * NumPy 的基本操作 创建全0矩阵和全1矩阵 12myZero = zeros([n,m])myOne = ones([n,m]) 生成随机矩阵 1myRand = random.rand(n,m) # n 行 m 列的 0～1 之间的随机数矩阵 生成单位矩阵 1myEye = eye(n) # n * n 的单位阵 将一个数组转化为一个矩阵 1myMatrix = mat([[1,2,3],[4,5,6],[7,8,9]]) 矩阵所有元素求和 1S = sum(myMatrix) 矩阵各元素的乘积 1matrix = multiply(matrix1, matrix2) # matrix1 和 matrix2 对应元素相乘的矩阵 求矩阵的 n 次幂 1matrix = power(myMatrix, n) #生成一个矩阵，矩阵内部的元素是原矩阵对应元素的n次幂 矩阵的转置 12print matrix.T #打印转置后的矩阵，不改变原矩阵matrix.transpose() #同上 矩阵的其他操作 1234567[m, n] = shape(matrix) # m, n为矩阵的行列数myscl1 = matrix[0] # 矩阵的切片操作，取第一行myscl2 = matrix.T[0] # 矩阵的切片操作，取第一列mycpmat = matrix.copy() # 矩阵的复制print matrix1 &lt; matrix2 # 矩阵的比较，会逐一比较对应的每一个元素，并输出一个仅包含True, False 的相同大小的矩阵dot(m1,m2) #计算m1,m2的点积norm(v) #计算向量V的范数 Linalg线性代数库 矩阵的行列式 1print linalg.det(matrix) 矩阵的逆 1print linalg.inv(matrix) 矩阵的对称 1print matrix * matrix.T 矩阵的秩 1print linalg.matrix_rank(A) 可逆矩阵求解 1print linalg.solve(A,b.T) # 如果b已经是一列的就不用转置了 各类距离的python实现 各类距离会在后面说明 Euclidean Distance 123vector1 = mat([1,2,3])vector2 = mat([4,5,6])print sqrt((vector1-vector2)*(vector1-vector2).T) Manhattan Distance 123vector1 = mat([1,2,3])vector2 = mat([4,5,6])print sum(abs(vector1-vector2)) Chebyshev Distance 123vector1 = mat([1,2,3])vector2 = mat([4,5,6])print abs(vector1-vector2).max() Cosine 12cosV12 = dot(vector1,vector2)/(linalg.norm(vector1)*linalg.norm(vector2))print cosV12 Hamming Distance 123matV = mat([[1,1,0,1,0,1,0,0,1], [0,1,1,0,0,0,1,1,1]])smstr = nonzero(matV[0] - matV[1]);print shape(smstr[0])[1] Jaccard Distance 123import scipy.spatial.distance as distmatV = mat([[1,1,0,1,0,1,0,0,1], [0,1,1,0,0,0,1,1,1]])print dist.pdist(matV, 'jaccard') 机器学习的数学基础 范数 向量的范数可以简单、形象的理解为向量的长度，或者向量到坐标系原点的距离，或者相应空间内的两点之间的距离 向量的范数定义 : 向量的范数是一个函数 $ \parallel x\parallel $ ,满足非负性 $ \parallel x\parallel &gt; 0 $ , 齐次性 $ \parallel cx\parallel = \mid c\mid\parallel x\parallel $ ,三角不等式 $ \parallel x+y\parallel \leq\parallel x\parallel +\parallel y\parallel $ 。 L1范数： $\parallel x\parallel $为 $ x $向量各个元素绝对值之和。L2范数： $\parallel x\parallel $为 $ x $向量各个元素平方和的开方，又称 Euclidean 范数或者 Frobenius 范数。Lp范数： $\parallel x\parallel $为 $ x $向量各个元素绝对值 $ p $次方和的 $ 1\over p $ 次方L $\infty $范数： $\parallel x\parallel $为 $ x $向量各个元素绝对值最大的那个元素，如下：$$ \lim_{k\to\infty}\left( \sum_{i=1}^n\mid p_i-q_i\mid ^k\right)^\frac{1}{k}$$ Minkowski Distance (闵可夫斯基距离) 严格意义上讲，Minkowski Distance 不是一种距离，而是一组距离的定义。两个n维向量 $ A(x_{11},x_{12},\cdots,x_{1n}) $ 与 $ B(x_{21},x_{22},\cdots,x_{2n}) $ 间的Minkowski距离定义为：$$ d_{12}=\sqrt[p]{\sum_{k=1}^n(x_{1k}-x_{2k})^p} $$其中p是一个变参数。 当 p=1 时，就是 Manhattan Distance (曼哈顿距离) 当 p=2 时，就是 Euclidean Distance (欧氏距离) 当 $ p\to\infty $ 时，就是 Chebyshev Distance (切比雪夫距离) Euclideam Distance 欧氏距离（L2范数）是最易于理解的一种距离计算方法，源于欧氏空间的两点距离公式两个n维向量 $ A(x_{11},x_{12},\cdots,x_{1n}) $ 与 $ B(x_{21},x_{22},\cdots,x_{2n}) $ 之间的欧氏距离：$$ d_{12}=\sqrt{\sum_{k=1}^n(x_{1k}-x_{2k})^2} $$表示为向量运算的形式：$$ d_{12}=\sqrt{(A - B)(A - B)^T} $$ Manhattan Distance 曼哈顿距离（L1范数）可以理解为计算网格中两点路径的距离二维平面两点 $ A(x_1,y_1) $ 和 $ B(x_2,y_2) $ 间的曼哈顿距离:$$ d_{12}=\mid x_1-x_2\mid +\mid y_1-y_2\mid $$两个n维向量 $ A(x_{11},x_{12},\cdots,x_{1n}) $ 与 $ B(x_{21},x_{22},\cdots,x_{2n}) $ 之间的曼哈顿距离：$$ d_{12}=\sum_{k=1}^n\mid x_{1k}-x_{2k}\mid $$ Chebyshev Distance 切比雪夫距离类似与棋盘上国王从一点到另一点移动的最少次数，即 $ max(\mid x_1-x_2\mid,\mid y_1-y_2\mid) $两个n维向量 $ A(x_{11},x_{12},\cdots,x_{1n}) $ 与 $ B(x_{21},x_{22},\cdots,x_{2n}) $ 之间的切比雪夫距离：$$ d_{12}=max_i(\mid x_{1i}-x_{2i}\mid) $$该公式的另一个等价公式：$$ d_{12}=\lim_{k\to\infty}\left(\sum_{i=1}^n\mid x_{1i}-x_{2i}\mid^k\right)^\frac{1}{k} $$ Cosine 夹角余弦可以用来两个向量方向的差异，机器学习中借用这一概念来衡量样本之间的差异两个n维向量 $ A(x_{11},x_{12},\cdots,x_{1n}) $ 与 $ B(x_{21},x_{22},\cdots,x_{2n}) $ 之间的夹角余弦：$$ \cos\theta=\frac{AB}{\mid A\mid\mid B\mid} $$即：$$ \cos\theta=\frac{\sum_{k=1}^nx_{1k}x_{2k}}{\sqrt{\sum_{k=1}^nx_{1k}^2}\sqrt{\sum_{k=1}^nx_{2k}^2}} $$ Hamming Distance 汉明距离的定义：两个等长字符串s1,s2,将其中一个变成另一个需要的最小替换次数。应用：信息编码（为了增强容错性，应使得编码间的最小汉明距离尽可能大） Jaccard Similarity Coefficient(杰卡德相似系数) 杰卡德相似系数：两个集合A,B的交集元素在并集元素中所占的比例，用符号 $ J(A,B) $ 表示$$ J(A,B)=\frac{\mid A\cap B\mid}{\mid A\cup B\mid} $$杰卡德距：与杰卡德相似系数相反的概念：$$ J_\delta(A,B)=1-J(A,B)=\frac{\mid A\cup B\mid-\mid A\cap B\mid}{\mid A\cup B\mid} $$ 特征间的相关性 相关系数与相关距离 相关系数： $$ \rho_{XY}=\frac{Cov(X,Y)}{\sqrt{D(X)}\sqrt{D(Y)}}=\frac{E((X-EX)(Y-EY))}{\sqrt{D(X)}\sqrt{D(Y)}} $$ 相关距离： $$ D_{XY}=1-\rho_{XY} $$python实现： 12345678910featuremat = mat(...) # 初始化矩阵# 计算均值mv1 = mean(featuremat[0]) # 计算第一列的均值mv2 = mean(featuremat[1]) # 计算第二列的均值#计算两列的标准差dv1 = std(featuremat[0]) dv2 = std(featuremat[1])corref = mean(multiply(featuremat[0]-mv1,featuremat[1]-mv2))/(dv1*dv2)print corref #输出相关系数print corrcoef(featuremat) #输出相关系数矩阵 马氏距离]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[重写博客]]></title>
    <url>%2F2016%2F01%2F22%2F%E9%87%8D%E5%86%99%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[一件很不幸的事，我重装系统的时候好像忘了把hexo的文章备份下来，结果那些markdown文档就都呵呵了 TAT～ 重新配置了一次hexo真的好麻烦，搞了半天，我真不知道我当时是怎么弄好的！ 之前的那些文章我还没有md文档，不过我倒是把整个博客给clone下来保存好了，以后如果有时间还是会恢复的吧。 这么快就放假了，然而真心觉得2015有点对不起自己，对不起这一年的时间。不过怎么说呢，后悔是没有用的，毕竟人要往前看嘛。只是希望2016结束的时候我不要还是这样，还是说出同样的话。 再不努力就老了！]]></content>
      <categories>
        <category>杂项</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[背包九讲]]></title>
    <url>%2F2015%2F07%2F21%2F%E8%83%8C%E5%8C%85%E4%B9%9D%E8%AE%B2%2F</url>
    <content type="text"><![CDATA[0/1背包问题 有N件物品和一个容量为V的背包。放入第i件物品耗费的空间是Ci，得到的价值是Wi。求解将哪些物品装入背包可使价值总和最大？ 将每一件物品从1到n编号，从第1件物品开始，每一件物品就只有两个状态：放进背包了 / 没有放进背包。 我们画一张表格，行对应着每一件物品，列对应着背包的重量，那么pack[i][j]就表示 前i件物品，背包最大承重j 这个子问题的解。 给一组数据作为样例： 5 10 6 2 3 2 5 6 4 5 6 4 第一行表示有5件物品，10为最大承重，2-6行为5个物品的价值和重量。 生成以下的表格 0 6 6 6 6 6 6 6 6 6 0 6 6 9 9 9 9 9 9 9 0 6 6 9 9 9 9 11 11 14 0 6 6 9 9 9 10 11 13 14 0 6 6 9 9 12 12 15 15 15 所以最终的结果是最后一行最后一列的 15 给出代码： 12345678910111213141516171819202122232425262728293031/* 01 package problem */#include &lt;iostream&gt;#include &lt;algorithm&gt;#include &lt;cstring&gt;using namespace std;int pack[100][1000];int c[100],w[100];void make(int n, int r)&#123; memset(pack,0,sizeof(pack)); for (int i = 1; i &lt;= n; i++) for (int j = w[i]; j &lt;= r; j++) pack[i][j] = max(pack[i - 1][j - c[i]] + w[i], pack[i - 1][j]); cout&lt;&lt;pack[n][r];&#125;int main()&#123; int t,n,V; cin&gt;&gt;t; while(t--)&#123; //多组数据 cin&gt;&gt;n&gt;&gt;V; for (int i = 1; i &lt;= n; i++) cin&gt;&gt;c[i]&gt;&gt;w[i]; make(n,V); &#125; return 0;&#125; 代码优化 这个代码在时间上应该已经不能再优化了，但是还可以考虑空间复杂度的优化。 优化的基本思路： 考虑所用到的状态转移方程: pack[i][j] = max(pack[i-1][j-c[i]] + w[i], pack[i-1][j]); 可以发现 pack[i][j] 的值并不和整个二维表的每一个数字的值都有关，而是仅仅和上面一行的值有关，所以可以使用 pack[2][n] 这么大的数组来存储结果。 考虑状态转移方程的实际情况，还可以使用一维数组来进行运算，但是要注意的是，此时，循环应该从后往前进行。因为如果是按从前往后的顺序，那么 pack[i][j] = max(pack[i][j-c[i]] + w[i] , pack[i][j]); 中进行比较的两个值 pack[i][j] 是没有更新的，也就是 pack[i-1][j] 的值，而 pack[i][j - c[i]]一定是前面被更新过的，也就是 pack[i][j-w[i]] 的值。这就是说，max() 比较的两个数是属于原来二维数组中不同的两行，而不是我们期望的相同的两行。 如果上面的说法不能理解我们不妨这样：有一件物品的性价比很高，在pack数组的某个位置，我们第一次将这个物品放入背包中，但是按照从前往后的顺序，很可能在这个位置的后面某个位置我们会再次将这个物品添加进去。 优化后的代码 12345678910111213141516171819202122232425#include &lt;iostream&gt;#include &lt;cstring&gt;using namespace std;int pack[10000],c[1000],w[1000];void make(int n, int r)&#123; memset(pack,0,sizeof(pack)); for (int i = 1; i &lt;= n; i++) for (int j = r; j &gt;= w[i]; j--) pack[j] = max(pack[j], pack[j - c[i]] + w[i]); cout&lt;&lt;pack[r]&lt;&lt;endl;&#125;int main()&#123; int n,t,V; cin&gt;&gt;t; while(t--)&#123; cin&gt;&gt;n&gt;&gt;V; for (int i = 1; i &lt;= n; i++) cin&gt;&gt;c[i]&gt;&gt;w[i]; make(n,V); &#125; return 0;&#125; 初始化问题： 如果限定背包必须装满，那么需要将数组初始化为 -∞ （负无穷大） 如果背包可以不装满，那么数组初始化为0 为了后面的书写方便，我们把代码改成这样1234void ZeroOnePack(int c,int w)&#123; for (int i = V; i &gt;= c; i--) pack[i] = max(pack[i], pack[i - c] + w);&#125; 这样01背包问题的主要代码就是这样： 12for (int i = 0; i &lt; n; i++) ZeroOnePack(c[i],w[i]); 这样ZeroOnePack()这个函数就专门解决了“放一个物品”的问题 完全背包问题 完全背包问题和0/1背包问题几乎一模一样，不同的就是物品不再是一个，而是无数个 思路 完全背包不同处是原来的一个物品变成了无数个，但是我们还是可以把它变成0/1背包问题的，试想一下，即使拥有无数个物品，但是真的可以用无数个吗？ 不可能，因为背包的容量有限，所以每个物品c,w最多可以使用[V/c]个，所以以下面的数据为例： c: 3 2 5 4 w: 7 4 2 5 V = 10 我们完全可以把这组数据改成这样： c: 3 3 3 2 2 2 2 2 5 5 4 4 w: 7 7 7 4 4 4 4 4 2 2 5 5 原因自然是背包容量最大为10,所以占用空间为3的物品最多放3个，修改过后的数据就可以用0/1背包的方法处理 那难道完全背包需要重开一个c2[],w2[]，然后按0/1背包处理吗？ 当然不是，还记得我们将0/1背包进行优化时说的如果循环从前向后进行会发生什么后果吗？ 这一句 “但是按照从前往后的顺序，很可能在这个位置的后面某个位置我们会再次将这个物品添加进去。” 看到了？0/1背包时为了避免重复，我们将循环改为从后往前，但是完全背包是可以重复使用物品的，对吧？所以代码： 1234void CompletePack(c,w)&#123; for (int i = c; i &lt;= V; i++) pack[i] = max(pack[i],pack[i - c] + w )&#125; 怎么样，和0/1背包只有一点点的差别对不对？ 3.多重背包问题 多重背包和0/1背包不同的地方就是物品不是一个而是有m个 所以我们还是就一个物品c,w,m分析： 对于m可能有两种情况： m &gt;= [V/c]，这种情况明显是完全背包 0 &lt; m &lt; [v/c]，对于这种情况需要认真分析一下 我们仍然需要按照0/1背包的思路把这些物品拆开，而且我们要保证我们拆出来的这些物品可以通过组合表示出1到m任意件物。 我们可以考虑二进制的计数方法，这样我们把物品拆成(c,w) , (2c,2w) , (4c,4w) …… [(m-2^k)*c , (m-2^k)*w)] 不管最优解会在这件物品中取几件，我们都可以用我们拆出来的这些物品来表示（请自己证明，二进制的思想） 所以，有了思路，代码就简单了： 12345678910111213void MultiplePack(c,w,m)&#123; if (c * m &gt;= V) &#123; CompletePack(c,w); return; &#125; k = 1; while (k &lt; m) &#123; ZeroOnePack(c*k,w*k); m = m - k; k = 2 * k; &#125; ZeroOnePack(c * m, w * m);&#125; 其实就是0/1背包和完全背包的组合，有木有？ 未完待续……]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
        <tag>背包问题</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下如何实现C语言的system("pause")]]></title>
    <url>%2F2015%2F04%2F15%2FLinux%E4%B8%8B%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0C%E8%AF%AD%E8%A8%80%E7%9A%84system-pause%2F</url>
    <content type="text"><![CDATA[getch() ? 不是标准库中的函数，在Linux中一般情况无法使用 getchar() + printf(“\b”) ? 貌似使用getchar()读入，再输出一个退格符将原来回显的字符删除应该是可以的，但是在实际试了一下发现根本不行。。。 原因：终端驱动器确实会读一个字符，但是他的输入只有到’\n’ 或 EOF 才会结束，所以如果不输入回车就不会实际执行getchar(). 当然，如果上一次输入的字符并没有全部读完是可以getchar()把没有读完的字符读掉。 解决办法123456789void system_pause(void)&#123; getchar(); puts("Press any key to continue..."); system("stty raw"); getchar(); system("stty cooked"); printf("\b");&#125; 这段代码也是我在网上找到的，我的理解是： getchar()读掉上面多余的’\n’，按程序的实际情况添加 输出”Press any key to continue…” system(“stty raw”);：将终端驱动器改为一次一个字符的模式，即输入一个字符就结束输入 getchar(); 读一个字符 system(“stty cooked”); 将终端驱动器改回一次一行的模式 printf(‘\b’); 退格，将回显的字符删除 p.s. 以上仅仅是个人理解，欢迎大家指出其中的错误]]></content>
      <categories>
        <category>C/C++</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>C/C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C/C++的一些有趣的区别]]></title>
    <url>%2F2015%2F03%2F17%2FC-C%2B%2B%E7%9A%84%E4%B8%80%E4%BA%9B%E6%9C%89%E8%B6%A3%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[在geeksforgeeks上看到一篇文章，说的是一些在C中可以编译但在C++中不行的程序，觉得比较好玩，就翻译分享一下啦。 在C++中，在main()中使用其它自定义的函数时必须在前面写上声明或者定义，但是在C中却可以写在main()的后面 123456789101112#include&lt;stdio.h&gt;int main()&#123; foo(); // foo() is called before its declaration/definition return 0;&#125; int foo()&#123; printf("Hello"); return 0; &#125; 上面的程序在C中可以编译成功，但是在C++中就不行 在C++中，指针是不能指向一个常量的，但是在C中可以 12345678910111213141516#include &lt;stdio.h&gt; int main(void)&#123; int const j = 20; /* The below assignment is invalid in C++, results in error In C, the compiler may throw a warning, but casting is implicitly allowed */ int *ptr = &amp;j; // A normal pointer points to const printf("*ptr: %d\n", *ptr); return 0;&#125; 在C语言中，一个空指针可以直接指派给其他指针，如int，char 。但在C中，必须指定类型 1234567#include &lt;stdio.h&gt;int main()&#123; void *vptr; int *iptr = vptr; //In C++, it must be replaced with int *iptr=(int *)vptr; return 0;&#125; 下面的程序在C中可以编译，但是在C++中不行，必须为常量初始化 123456#include &lt;stdio.h&gt;int main()&#123; const int a; // LINE 4 return 0;&#125; Line 4 [Error] uninitialized const ‘a’ [-fpermissive] 在C中可以用C++的一些特定的关键字作为变量名 p.s. 这是自然，汗 123456#include &lt;stdio.h&gt;int main(void)&#123; int new = 5; // new is a keyword in C++, but not in C printf("%d", new);&#125; C++的检查会比C更严格，如： 1234567#include &lt;stdio.h&gt;int main()&#123; char *c = 333; printf("c = %u", c); return 0;&#125; error “invalid conversion from ‘int’ to ‘char*’”. 试了一些，确实是这样，感觉蛮有趣的！ 原文链接]]></content>
      <categories>
        <category>C/C++</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[我的第一篇博客]]></title>
    <url>%2F2015%2F03%2F15%2F%E6%88%91%E7%9A%84%E7%AC%AC%E4%B8%80%E7%AF%87%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[为了搞这个博客我确实花了不少功夫，从昨天晚上12点左右就开始了，看教程啊，然后自己操作去搞。加上一些教程由于时间的问题，总是存在着一些坑要填。不过麻烦归麻烦，我也总算是在3点的时候把东西推到github上面去了。 今天在申请免费的一级域名，免费的太难找到了，找到的又都是坑。反正这段时间域名解析什么的就慢慢来吧，不着急。 以前没有认真看markdown，只是能把每次的东西更新到tower上就满足了。现在还是认真看看markdown吧，毕竟写就要认真写。 p.s. 附上一个大坑，也提醒一下我自己一定记住冒号后面留一个空格]]></content>
      <categories>
        <category>杂项</category>
      </categories>
  </entry>
</search>
